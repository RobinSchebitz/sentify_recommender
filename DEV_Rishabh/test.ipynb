{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working on Spotify Playlist\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing libraries and setting up authentication with Spotify API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing data from Spotify dataset\n",
    "\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyOAuth\n",
    "\n",
    "# Replace 'your_client_id', 'your_client_secret', and 'your_redirect_uri' with your actual values\n",
    "sp = spotipy.Spotify(auth_manager=SpotifyOAuth(\n",
    "    client_id='5093ad0ad45f435ca7ce43b2afd406b9',\n",
    "    client_secret='f151962f414144aa85494be81ccd8e20',\n",
    "    redirect_uri='http://localhost:8888/callback',\n",
    "    scope=\"user-library-read playlist-read-private\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetching data from Spotify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''playlist_id = '6JOysTE0drK9yDi1Xs4FKy'  # Replace with the actual playlist ID\n",
    "playlist = sp.playlist(playlist_id)\n",
    "print(playlist['name'])\n",
    "for item in playlist['tracks']['items']:\n",
    "    track = item['track']\n",
    "    print(track['name'], '-', track['artists'][0]['name'])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Fetch saved tracks\n",
    "playlist_id = '6JOysTE0drK9yDi1Xs4FKy'\n",
    "\n",
    "results = sp.playlist_tracks(playlist_id)\n",
    "tracks_data = {\n",
    "    'Name': [],\n",
    "    'Artist': [],\n",
    "    'Album': [],\n",
    "    'Release Date': []\n",
    "}\n",
    "\n",
    "for item in results['items']:\n",
    "    track = item.get('track')\n",
    "    if track:  # Check if track details are present\n",
    "        name = track.get('name', 'No Title Available')\n",
    "        artist_name = track['artists'][0].get('name', 'No Artist Available') if track['artists'] else 'No Artists'\n",
    "        album_name = track['album'].get('name', 'No Album Available') if track['album'] else 'No Album'\n",
    "        release_date = track['album'].get('release_date', 'No Release Date Available') if track['album'] else 'No Release Info'\n",
    "        \n",
    "        tracks_data['Name'].append(name)\n",
    "        tracks_data['Artist'].append(artist_name)\n",
    "        tracks_data['Album'].append(album_name)\n",
    "        tracks_data['Release Date'].append(release_date)\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_tracks = pd.DataFrame(tracks_data)\n",
    "print(df_tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyOAuth\n",
    "\n",
    "# Initialize the Spotify client\n",
    "sp = spotipy.Spotify(auth_manager=SpotifyOAuth(\n",
    "    client_id='your_client_id',\n",
    "    client_secret='your_client_secret',\n",
    "    redirect_uri='http://localhost:8888/callback',\n",
    "    scope='user-library-read'))\n",
    "\n",
    "# Search for tracks by genre\n",
    "genre = \"rock\"  # Example genre\n",
    "results = sp.search(q='genre:' + genre, type='track', limit=50)\n",
    "tracks_data = {\n",
    "    'Name': [],\n",
    "    'Artist': [],\n",
    "    'Genre': genre,\n",
    "    'Popularity': []\n",
    "}\n",
    "\n",
    "for track in results['tracks']['items']:\n",
    "    tracks_data['Name'].append(track['name'])\n",
    "    tracks_data['Artist'].append(track['artists'][0]['name'])\n",
    "    tracks_data['Popularity'].append(track['popularity'])\n",
    "\n",
    "# Print or process the results\n",
    "print([tracks_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing Song Data with Lyrics using Genius API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lyricsgenius\n",
    "\n",
    "# Initialize Genius API\n",
    "genius = lyricsgenius.Genius('put_your_token_here')\n",
    "\n",
    "genius.remove_section_headers = True\n",
    "\n",
    "# Spotify Global Top 50 playlist ID\n",
    "playlist_id = '37i9dQZEVXbMDoHDwVN2tF'  # Example ID, update as necessary\n",
    "\n",
    "results = sp.playlist_tracks(playlist_id)\n",
    "tracks_data = []\n",
    "\n",
    "# Fetch track details from Spotify\n",
    "for item in results['items']:\n",
    "    track = item['track']\n",
    "    track_info = {\n",
    "        'Name': track['name'],\n",
    "        'Artist': track['artists'][0]['name'] if track['artists'] else 'Unknown',\n",
    "        'Album': track['album']['name'] if track['album'] else 'Unknown',\n",
    "        'Release Date': track['album']['release_date'] if track['album'] else 'Unknown',\n",
    "        'Popularity': track['popularity']\n",
    "    }\n",
    "    # Fetch lyrics using Genius\n",
    "    song = genius.search_song(track_info['Name'], track_info['Artist'])\n",
    "    track_info['Lyrics'] = song.lyrics if song else 'Lyrics not found'\n",
    "    \n",
    "    tracks_data.append(track_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert the data to a pandas DataFrame\n",
    "df_tracks = pd.DataFrame(tracks_data)\n",
    "\n",
    "# Set column names and display the DataFrame\n",
    "df_tracks.columns = ['Track Name', 'Artist', 'Album', 'Release Date', 'Popularity', 'Lyrics']\n",
    "print(df_tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save DataFrame to CSV file\n",
    "df_tracks.to_csv('spotify_songs_with_lyrics.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tracks.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing data\n",
    "\n",
    "Clean the lyrics by removing punctuation, converting to lowercase, and other typical text cleaning steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Removeing punctuation\n",
    "    text = text.lower()  # Convert to lower case\n",
    "    return text\n",
    "\n",
    "# Apply the cleaning function to the lyrics column\n",
    "df_tracks['cleaned_lyrics'] = df_tracks['Lyrics'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize a TF-IDF Vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(df_tracks['cleaned_lyrics'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis using VADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# Initialize the VADER sentiment intensity analyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Function to get the compound sentiment score\n",
    "def get_sentiment(text):\n",
    "    score = analyzer.polarity_scores(text)\n",
    "    return score['compound']  # Return the compound score\n",
    "\n",
    "# Apply the sentiment analysis function to the cleaned lyrics\n",
    "df_tracks['sentiment_score'] = df_tracks['cleaned_lyrics'].apply(get_sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign Sentiment Labels\n",
    "\n",
    "Classifying the sentiments as positive, neutral or negative based on the computed score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_sentiment(score):\n",
    "    if score > 0.05:\n",
    "        return 'positive'\n",
    "    elif score < -0.05:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'\n",
    "\n",
    "# Apply sentiment label assignment\n",
    "df_tracks['sentiment_label'] = df_tracks['sentiment_score'].apply(assign_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_tracks[['Track Name', 'Artist', 'sentiment_score', 'sentiment_label']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tracks[['Track Name', 'Artist', 'sentiment_score', 'sentiment_label']].to_csv('test_sentiment.csv', index=False)\n",
    "\n",
    "test_sentiment = pd.read_csv('test_sentiment.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Json file to Pandas readable format\n",
    "\n",
    "Start by importing spotify challenge (AI Crowd) file into python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load JSON data from file\n",
    "with open('/Users/rishabhhasija/Documents/neuefische/sentify_recommender/data/challenge_set.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Initialize an empty list to collect all track data\n",
    "all_tracks = []\n",
    "\n",
    "# Loop through each playlist in the dataset\n",
    "for playlist in data['playlists']:\n",
    "    for track in playlist['tracks']:\n",
    "        # Add playlist-level information to each track record\n",
    "        track_info = {\n",
    "            'playlist_name': playlist.get('name', 'Unknown'),\n",
    "            'playlist_pid': playlist['pid'],\n",
    "            'playlist_num_tracks': playlist['num_tracks'],\n",
    "            'track_pos': track['pos'],\n",
    "            'artist_name': track['artist_name'],\n",
    "            'track_uri': track['track_uri'],\n",
    "            'artist_uri': track['artist_uri'],\n",
    "            'track_name': track['track_name'],\n",
    "            'album_uri': track['album_uri'],\n",
    "            'duration_ms': track['duration_ms'],\n",
    "            'album_name': track['album_name']\n",
    "        }\n",
    "        all_tracks.append(track_info)\n",
    "\n",
    "# Convert the list of track dictionaries to a DataFrame\n",
    "df_spotify = pd.DataFrame(all_tracks)\n",
    "\n",
    "# Display the first few rows of the DataFrame to verify\n",
    "#print(df_spotify.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(281000, 11)\n"
     ]
    }
   ],
   "source": [
    "print(df_spotify.shape)\n",
    "#print(df_spotify.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['playlist_name', 'playlist_pid', 'playlist_num_tracks', 'track_pos',\n",
       "       'artist_name', 'track_uri', 'artist_uri', 'track_name', 'album_uri',\n",
       "       'duration_ms', 'album_name'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spotify.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_spotify\n",
    "#df_lyrics = df_spotify['track_uri'].unique()  \n",
    "df_lyrics = df_spotify.drop_duplicates(subset=['track_uri']).drop(['playlist_name', 'playlist_pid', 'playlist_num_tracks', 'track_pos', 'artist_name',\n",
    "       'artist_uri', 'track_name', 'album_uri', 'duration_ms', 'album_name'], axis=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66243, 1)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lyrics.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47397, 1)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mini_df = df_lyrics.head(47397)\n",
    "mini_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lyrics.to_csv('df_lyrics.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_df.to_csv('mini_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "import time\n",
    "\n",
    "auth_manager = SpotifyClientCredentials(client_id='59cdbf840d9245118927fc195c3e4e0a', client_secret='f3b0a7237fb04ca2ba9fc6bbefb729b7')\n",
    "sp = spotipy.Spotify(auth_manager=auth_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "#def file_exists_and_not_empty(file_name):\n",
    "    return os.path.isfile(file_name) and os.stat(file_name).st_size > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_batch(batch_data):\n",
    "    # Creating an empty DataFrame to store updated data\n",
    "    processed_data = pd.DataFrame(columns=['track_uri', 'artist_name', 'track_name'])\n",
    "    \n",
    "    # Iterating over the batch_data to fetch details from Spotify\n",
    "    for i, uri in enumerate(batch_data['track_uri']):\n",
    "        try:\n",
    "            track = sp.track(uri)\n",
    "            processed_data.loc[i, 'track_uri'] = uri\n",
    "            processed_data.loc[i, 'artist_name'] = track['artists'][0]['name']\n",
    "            processed_data.loc[i, 'track_name'] = track['name']\n",
    "            print(i)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {uri}: {e}\")\n",
    "    return processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "chunk_size = 10\n",
    "csv_file = \"mini_df.csv\"  # Path to input CSV file\n",
    "output_file = \"mini_test.csv\"  # Path to save the processed data\n",
    "\n",
    "start_row = 46244 # Adjust row number from which processing needs to be started\n",
    "\n",
    "# Read the CSV file in batches and process each batch\n",
    "for chunk in pd.read_csv(csv_file, chunksize=chunk_size, skiprows=range(1, start_row)):\n",
    "    time.sleep(5)\n",
    "    processed_chunk = process_batch(chunk)\n",
    "    # Append each processed chunk to the output file\n",
    "    processed_chunk.to_csv(output_file, mode=\"a\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_uri</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>track_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spotify:track:66U0ASk1VHZsqIkpMjKX3B</td>\n",
       "      <td>AronChupa</td>\n",
       "      <td>Little Swing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spotify:track:5MhsZlmKJG6X5kTHkdwC4B</td>\n",
       "      <td>AronChupa</td>\n",
       "      <td>I'm an Albatraoz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spotify:track:0GZoB8h0kqXn7XFm4Sj06k</td>\n",
       "      <td>Lorde</td>\n",
       "      <td>Yellow Flicker Beat - From The Hunger Games: M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spotify:track:35kahykNu00FPysz3C2euR</td>\n",
       "      <td>Lorde</td>\n",
       "      <td>White Teeth Teens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spotify:track:3G6hD9B2ZHOsgf4WfNu7X1</td>\n",
       "      <td>Lorde</td>\n",
       "      <td>Team</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              track_uri artist_name   \n",
       "0  spotify:track:66U0ASk1VHZsqIkpMjKX3B   AronChupa  \\\n",
       "1  spotify:track:5MhsZlmKJG6X5kTHkdwC4B   AronChupa   \n",
       "2  spotify:track:0GZoB8h0kqXn7XFm4Sj06k       Lorde   \n",
       "3  spotify:track:35kahykNu00FPysz3C2euR       Lorde   \n",
       "4  spotify:track:3G6hD9B2ZHOsgf4WfNu7X1       Lorde   \n",
       "\n",
       "                                          track_name  \n",
       "0                                       Little Swing  \n",
       "1                                   I'm an Albatraoz  \n",
       "2  Yellow Flicker Beat - From The Hunger Games: M...  \n",
       "3                                  White Teeth Teens  \n",
       "4                                               Team  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading dataset & assigning column names\n",
    "df1 = pd.read_csv('mini_test.csv', header=None)\n",
    "df1.columns = ['track_uri', 'artist_name', 'track_name']\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47387, 3)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df1[df1.duplicated(keep=False)]\n",
    "df1_unique = df1.drop_duplicates(keep='first')\n",
    "df1_unique.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_uri</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>track_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spotify:track:38griAVM808crjbFp9gcPD</td>\n",
       "      <td>El Gran Combo De Puerto Rico</td>\n",
       "      <td>Y No Hago Mas Na' - Reggaeton Mix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spotify:track:1cKRBp7hrBVD4eP3W9x2AI</td>\n",
       "      <td>Alice Deejay</td>\n",
       "      <td>Better Off Alone - Vocal Club RMX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spotify:track:5JugcqxQihVYdvCSPzmP1H</td>\n",
       "      <td>Bastille</td>\n",
       "      <td>Campus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spotify:track:2PBTwMH2mzfLigdMyPzOcp</td>\n",
       "      <td>2 LIVE CREW</td>\n",
       "      <td>Pop That P--sy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spotify:track:3p5vcN5Q9JawdzBbh5ceVr</td>\n",
       "      <td>The Royal Movie Band</td>\n",
       "      <td>Starman</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              track_uri                   artist_name   \n",
       "0  spotify:track:38griAVM808crjbFp9gcPD  El Gran Combo De Puerto Rico  \\\n",
       "1  spotify:track:1cKRBp7hrBVD4eP3W9x2AI                  Alice Deejay   \n",
       "2  spotify:track:5JugcqxQihVYdvCSPzmP1H                      Bastille   \n",
       "3  spotify:track:2PBTwMH2mzfLigdMyPzOcp                   2 LIVE CREW   \n",
       "4  spotify:track:3p5vcN5Q9JawdzBbh5ceVr          The Royal Movie Band   \n",
       "\n",
       "                          track_name  \n",
       "0  Y No Hago Mas Na' - Reggaeton Mix  \n",
       "1  Better Off Alone - Vocal Club RMX  \n",
       "2                             Campus  \n",
       "3                     Pop That P--sy  \n",
       "4                            Starman  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv('/Users/rishabhhasija/Documents/neuefische/sentify_recommender/DEV_Robin/output_robin.csv', header=None)\n",
    "df2.columns = ['track_uri', 'artist_name', 'track_name']\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(67317, 3)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = ['df1', 'df2']\n",
    "\n",
    "#data2 = [pd.read_csv(f) for f in data1]\n",
    "spotify_data1 = pd.concat([df1, df2], ignore_index=True)\n",
    "spotify_data1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify_data = spotify_data1.drop_duplicates(keep='first')\n",
    "#spotify_data.shape\n",
    "spotify_data.to_csv('spotify_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting File into multiple files of fixed row size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_per_file = 3000  # Number of rows per file\n",
    "\n",
    "# Calculate how many files will be needed\n",
    "num_files = len(df_lyrics) // rows_per_file + (1 if len(df_lyrics) % rows_per_file != 0 else 0)\n",
    "\n",
    "# Split and save the DataFrame into multiple CSV files\n",
    "for i in range(num_files):\n",
    "    start_row = i * rows_per_file\n",
    "    end_row = start_row + rows_per_file\n",
    "    # Create a new CSV file for each chunk\n",
    "    df_lyrics[start_row:end_row].to_csv(f'output_file_{i + 1}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fetching Lyrics from Genius API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import lyricsgenius\n",
    "\n",
    "load_dotenv()\n",
    "token = os.getenv(\"genius_token\")\n",
    "genius = lyricsgenius.Genius(token)\n",
    "genius.remove_section_headers = True # Remove section headers from lyrics when searching\n",
    "genius.timeout = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching lyrics via API\n",
    "for i in range(len(df_lyrics)-66233):\n",
    "    df_lyrics.loc[i, 'lyrics'] = genius.search_song(df_lyrics['track_name'][i], df_lyrics['artist_name'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df_lyrics)-1):\n",
    "    song = genius.search_song(df_lyrics['track_name'][i], df_lyrics['artist_name'][i])\n",
    "    df_lyrics.loc[i, 'lyrics'] = song.lyrics if song else 'Lyrics not found'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lyrics['lyrics'][7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"131 ContributorsTranslationsEspañolFrançaisItalianoPortuguêsTeam Lyrics\\nWait till you're announced\\nWe've not yet lost all our graces\\nThe hounds will stay in chains\\nLook upon Your Greatness and she'll\\nSend the call out, send the call out\\nSend the call out, send the call out\\nSend the call out, send the call out\\nSend the call out, send the call out\\nSend the call out, send the call out\\nSend the call out, send the call out\\nSend the call out, send the call out\\nSend the call out, send the call out\\n\\nCall all the ladies out\\nThey're in their finery\\nA hundred jewels on throats\\nA hundred jewels between teeth\\nNow bring my boys in\\nTheir skin in craters like the moon\\nThe moon we love like a brother\\nWhile he glows through the room\\n\\nDancin' around the lies we tell\\nDancin' around big eyes, as well\\nEven the comatose\\nThey don't dance and tell\\nYou might also like\\nWe live in cities you'll never see on-screen\\nNot very pretty, but we sure know how to run things\\nLivin' in ruins of a palace within my dreams\\nAnd you know, we're on each other's team\\n\\nI'm kind of over gettin' told to throw my hands up in the air\\nSo there\\n\\nSo all the cups got broke\\nShards beneath our feet\\nBut it wasn't my fault\\nAnd everyone's competing\\nFor a love they won't receive\\n'Cause what this palace wants is release\\n\\nWe live in cities you'll never see on-screen\\nNot very pretty, but we sure know how to run things\\nLivin' in ruins of a palace within my dreams\\nAnd you know, we're on each other's team\\n\\nI'm kind of over gettin' told to throw my hands up in the air\\nSo there\\nI'm kind of older than I was when I reveled without a care\\nSo there\\nWe live in cities you'll never see on-screen\\nNot very pretty, but we sure know how to run things\\nLivin' in ruins of a palace within my dreams\\nAnd you know, we're on each other's team\\n\\nWe're on each other's team\\nAnd you know, we're on each other's team\\nWe're on each other's team\\nAnd you know, and you know, and you know330Embed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lyrics['lyrics'].isna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lyricsgenius\n",
    "\n",
    "# Initialize Genius API\n",
    "genius = lyricsgenius.Genius('put_your_token_here')\n",
    "\n",
    "genius.remove_section_headers = True\n",
    "\n",
    "# Spotify Global Top 50 playlist ID\n",
    "playlist_id = '37i9dQZEVXbMDoHDwVN2tF'  # Example ID, update as necessary\n",
    "\n",
    "results = sp.playlist_tracks(playlist_id)\n",
    "tracks_data = []\n",
    "\n",
    "# Fetch track details from Spotify\n",
    "for item in results['items']:\n",
    "    track = item['track']\n",
    "    track_info = {\n",
    "        'Name': track['name'],\n",
    "        'Artist': track['artists'][0]['name'] if track['artists'] else 'Unknown',\n",
    "        'Album': track['album']['name'] if track['album'] else 'Unknown',\n",
    "        'Release Date': track['album']['release_date'] if track['album'] else 'Unknown',\n",
    "        'Popularity': track['popularity']\n",
    "    }\n",
    "    # Fetch lyrics using Genius\n",
    "    song = genius.search_song(track_info['Name'], track_info['Artist'])\n",
    "    track_info['Lyrics'] = song.lyrics if song else 'Lyrics not found'\n",
    "    \n",
    "    tracks_data.append(track_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the lyrics column if it doesn't exist\n",
    "if 'lyrics' not in df_lyrics.columns:\n",
    "    df_lyrics['lyrics'] = None\n",
    "\n",
    "# Defining batch size for progress tracking\n",
    "batch_size = 100\n",
    "num_batches = (len(df_lyrics) + batch_size - 1) // batch_size  # Calculate total number of batches\n",
    "\n",
    "# Processing each song in df_lyrics\n",
    "for i in range(len(df_lyrics)):\n",
    "    if pd.isna(df_lyrics.at[i, 'lyrics']):  # Check if lyrics already fetched to avoid refetching\n",
    "        try:\n",
    "            song = genius.search_song(df_lyrics.at[i, 'track_name'], df_lyrics.at[i, 'artist_name'])\n",
    "            df_lyrics.at[i, 'lyrics'] = song.lyrics if song else 'Lyrics not found'\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching lyrics for row {i}: {e}\")\n",
    "            df_lyrics.at[i, 'lyrics'] = 'Error fetching lyrics'\n",
    "    # Checking print progress\n",
    "    if i % batch_size == 0 or i == len(df_lyrics) - 1:\n",
    "        print(f\"Processed {i+1}/{len(df_lyrics)} songs, Batch {i // batch_size + 1}/{num_batches}\")\n",
    "\n",
    "# Saving complete DataFrame with lyrics to a new file\n",
    "df_lyrics.to_csv('df_final.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save DataFrame to CSV file\n",
    "df_lyrics.to_csv('spotify_lyrics.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lyrics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''import pandas as pd\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "\n",
    "# Initialize spotipy with Spotify API credentials\n",
    "client_id = '5093ad0ad45f435ca7ce43b2afd406b9'  # Replace with your client ID\n",
    "client_secret = 'f151962f414144aa85494be81ccd8e20'  # Replace with your client secret\n",
    "client_credentials_manager = SpotifyClientCredentials(client_id=client_id, client_secret=client_secret)\n",
    "sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)'''\n",
    "\n",
    "# Function to fetch artist name and track name\n",
    "def fetch_tracks_details(track_uris):\n",
    "    try:\n",
    "        tracks_info = sp.tracks(track_uris)\n",
    "        results = []\n",
    "        for track in tracks_info['tracks']:\n",
    "            if track:  # Check if track details are successfully retrieved\n",
    "                artist_name = track['artists'][0]['name'] if track['artists'] else 'Unknown'\n",
    "                track_name = track['name'] if track else 'Unknown'\n",
    "                results.append((artist_name, track_name))\n",
    "            else:\n",
    "                results.append(('Unknown', 'Unknown'))\n",
    "        return results\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing batch: {str(e)}\")\n",
    "        return [('Unknown', 'Unknown')] * len(track_uris)\n",
    "\n",
    "# Apply batch processing\n",
    "batch_size = 50\n",
    "artist_names = []\n",
    "track_names = []\n",
    "\n",
    "for i in range(0, len(df_lyrics['track_uri']), batch_size):\n",
    "    batch_uris = df_lyrics['track_uri'][i:i + batch_size].tolist()\n",
    "    batch_results = fetch_tracks_details(batch_uris)\n",
    "    artist_names.extend([res[0] for res in batch_results])\n",
    "    track_names.extend([res[1] for res in batch_results])\n",
    "\n",
    "df_lyrics['alb_name'] = artist_names\n",
    "df_lyrics['trk_name'] = track_names\n",
    "\n",
    "# Save the updated DataFrame\n",
    "df_lyrics.to_csv('df_lyrics_updated.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
