{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working on Spotify Playlist\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing libraries and setting up authentication with Spotify API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing data from Spotify dataset\n",
    "\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyOAuth\n",
    "\n",
    "# Replace 'your_client_id', 'your_client_secret', and 'your_redirect_uri' with your actual values\n",
    "sp = spotipy.Spotify(auth_manager=SpotifyOAuth(\n",
    "    client_id='5093ad0ad45f435ca7ce43b2afd406b9',\n",
    "    client_secret='f151962f414144aa85494be81ccd8e20',\n",
    "    redirect_uri='http://localhost:8888/callback',\n",
    "    scope=\"user-library-read playlist-read-private\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetching data from Spotify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''playlist_id = '6JOysTE0drK9yDi1Xs4FKy'  # Replace with the actual playlist ID\n",
    "playlist = sp.playlist(playlist_id)\n",
    "print(playlist['name'])\n",
    "for item in playlist['tracks']['items']:\n",
    "    track = item['track']\n",
    "    print(track['name'], '-', track['artists'][0]['name'])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Fetch saved tracks\n",
    "playlist_id = '6JOysTE0drK9yDi1Xs4FKy'\n",
    "\n",
    "results = sp.playlist_tracks(playlist_id)\n",
    "tracks_data = {\n",
    "    'Name': [],\n",
    "    'Artist': [],\n",
    "    'Album': [],\n",
    "    'Release Date': []\n",
    "}\n",
    "\n",
    "for item in results['items']:\n",
    "    track = item.get('track')\n",
    "    if track:  # Check if track details are present\n",
    "        name = track.get('name', 'No Title Available')\n",
    "        artist_name = track['artists'][0].get('name', 'No Artist Available') if track['artists'] else 'No Artists'\n",
    "        album_name = track['album'].get('name', 'No Album Available') if track['album'] else 'No Album'\n",
    "        release_date = track['album'].get('release_date', 'No Release Date Available') if track['album'] else 'No Release Info'\n",
    "        \n",
    "        tracks_data['Name'].append(name)\n",
    "        tracks_data['Artist'].append(artist_name)\n",
    "        tracks_data['Album'].append(album_name)\n",
    "        tracks_data['Release Date'].append(release_date)\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_tracks = pd.DataFrame(tracks_data)\n",
    "print(df_tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyOAuth\n",
    "\n",
    "# Initialize the Spotify client\n",
    "sp = spotipy.Spotify(auth_manager=SpotifyOAuth(\n",
    "    client_id='your_client_id',\n",
    "    client_secret='your_client_secret',\n",
    "    redirect_uri='http://localhost:8888/callback',\n",
    "    scope='user-library-read'))\n",
    "\n",
    "# Search for tracks by genre\n",
    "genre = \"rock\"  # Example genre\n",
    "results = sp.search(q='genre:' + genre, type='track', limit=50)\n",
    "tracks_data = {\n",
    "    'Name': [],\n",
    "    'Artist': [],\n",
    "    'Genre': genre,\n",
    "    'Popularity': []\n",
    "}\n",
    "\n",
    "for track in results['tracks']['items']:\n",
    "    tracks_data['Name'].append(track['name'])\n",
    "    tracks_data['Artist'].append(track['artists'][0]['name'])\n",
    "    tracks_data['Popularity'].append(track['popularity'])\n",
    "\n",
    "# Print or process the results\n",
    "print([tracks_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing Song Data with Lyrics using Genius API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lyricsgenius\n",
    "\n",
    "# Initialize Genius API\n",
    "genius = lyricsgenius.Genius('put_your_token_here')\n",
    "\n",
    "genius.remove_section_headers = True\n",
    "\n",
    "# Spotify Global Top 50 playlist ID\n",
    "playlist_id = '37i9dQZEVXbMDoHDwVN2tF'  # Example ID, update as necessary\n",
    "\n",
    "results = sp.playlist_tracks(playlist_id)\n",
    "tracks_data = []\n",
    "\n",
    "# Fetch track details from Spotify\n",
    "for item in results['items']:\n",
    "    track = item['track']\n",
    "    track_info = {\n",
    "        'Name': track['name'],\n",
    "        'Artist': track['artists'][0]['name'] if track['artists'] else 'Unknown',\n",
    "        'Album': track['album']['name'] if track['album'] else 'Unknown',\n",
    "        'Release Date': track['album']['release_date'] if track['album'] else 'Unknown',\n",
    "        'Popularity': track['popularity']\n",
    "    }\n",
    "    # Fetch lyrics using Genius\n",
    "    song = genius.search_song(track_info['Name'], track_info['Artist'])\n",
    "    track_info['Lyrics'] = song.lyrics if song else 'Lyrics not found'\n",
    "    \n",
    "    tracks_data.append(track_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert the data to a pandas DataFrame\n",
    "df_tracks = pd.DataFrame(tracks_data)\n",
    "\n",
    "# Set column names and display the DataFrame\n",
    "df_tracks.columns = ['Track Name', 'Artist', 'Album', 'Release Date', 'Popularity', 'Lyrics']\n",
    "print(df_tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save DataFrame to CSV file\n",
    "df_tracks.to_csv('spotify_songs_with_lyrics.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tracks.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing data\n",
    "\n",
    "Clean the lyrics by removing punctuation, converting to lowercase, and other typical text cleaning steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Removeing punctuation\n",
    "    text = text.lower()  # Convert to lower case\n",
    "    return text\n",
    "\n",
    "# Apply the cleaning function to the lyrics column\n",
    "df_tracks['cleaned_lyrics'] = df_tracks['Lyrics'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize a TF-IDF Vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(df_tracks['cleaned_lyrics'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis using VADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# Initialize the VADER sentiment intensity analyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Function to get the compound sentiment score\n",
    "def get_sentiment(text):\n",
    "    score = analyzer.polarity_scores(text)\n",
    "    return score['compound']  # Return the compound score\n",
    "\n",
    "# Apply the sentiment analysis function to the cleaned lyrics\n",
    "df_tracks['sentiment_score'] = df_tracks['cleaned_lyrics'].apply(get_sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign Sentiment Labels\n",
    "\n",
    "Classifying the sentiments as positive, neutral or negative based on the computed score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_sentiment(score):\n",
    "    if score > 0.05:\n",
    "        return 'positive'\n",
    "    elif score < -0.05:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'\n",
    "\n",
    "# Apply sentiment label assignment\n",
    "df_tracks['sentiment_label'] = df_tracks['sentiment_score'].apply(assign_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_tracks[['Track Name', 'Artist', 'sentiment_score', 'sentiment_label']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tracks[['Track Name', 'Artist', 'sentiment_score', 'sentiment_label']].to_csv('test_sentiment.csv', index=False)\n",
    "\n",
    "test_sentiment = pd.read_csv('test_sentiment.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Json file to Pandas readable format\n",
    "\n",
    "Start by importing spotify challenge (AI Crowd) file into python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load JSON data from file\n",
    "with open('/Users/rishabhhasija/Documents/neuefische/sentify_recommender/data/challenge_set.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Initialize an empty list to collect all track data\n",
    "all_tracks = []\n",
    "\n",
    "# Loop through each playlist in the dataset\n",
    "for playlist in data['playlists']:\n",
    "    for track in playlist['tracks']:\n",
    "        # Add playlist-level information to each track record\n",
    "        track_info = {\n",
    "            'playlist_name': playlist.get('name', 'Unknown'),\n",
    "            'playlist_pid': playlist['pid'],\n",
    "            'playlist_num_tracks': playlist['num_tracks'],\n",
    "            'track_pos': track['pos'],\n",
    "            'artist_name': track['artist_name'],\n",
    "            'track_uri': track['track_uri'],\n",
    "            'artist_uri': track['artist_uri'],\n",
    "            'track_name': track['track_name'],\n",
    "            'album_uri': track['album_uri'],\n",
    "            'duration_ms': track['duration_ms'],\n",
    "            'album_name': track['album_name']\n",
    "        }\n",
    "        all_tracks.append(track_info)\n",
    "\n",
    "# Convert the list of track dictionaries to a DataFrame\n",
    "df_spotify = pd.DataFrame(all_tracks)\n",
    "\n",
    "# Display the first few rows of the DataFrame to verify\n",
    "#print(df_spotify.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lyrics Code & Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_spotify.shape)\n",
    "#print(df_spotify.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spotify.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spotify['playlist_num_tracks'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_spotify\n",
    "#df_lyrics = df_spotify['track_uri'].unique()  \n",
    "df_lyrics = df_spotify.drop_duplicates(subset=['track_uri']).drop(['playlist_name', 'playlist_pid', 'playlist_num_tracks', 'track_pos', 'artist_name',\n",
    "       'artist_uri', 'track_name', 'album_uri', 'duration_ms', 'album_name'], axis=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lyrics.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_df = df_lyrics.head(47397)\n",
    "mini_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lyrics.to_csv('df_lyrics.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_df.to_csv('mini_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "import time\n",
    "\n",
    "auth_manager = SpotifyClientCredentials(client_id='59cdbf840d9245118927fc195c3e4e0a', client_secret='f3b0a7237fb04ca2ba9fc6bbefb729b7')\n",
    "sp = spotipy.Spotify(auth_manager=auth_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "#def file_exists_and_not_empty(file_name):\n",
    "#    return os.path.isfile(file_name) and os.stat(file_name).st_size > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_batch(batch_data):\n",
    "    # Creating an empty DataFrame to store updated data\n",
    "    processed_data = pd.DataFrame(columns=['track_uri', 'artist_name', 'track_name'])\n",
    "    \n",
    "    # Iterating over the batch_data to fetch details from Spotify\n",
    "    for i, uri in enumerate(batch_data['track_uri']):\n",
    "        try:\n",
    "            track = sp.track(uri)\n",
    "            processed_data.loc[i, 'track_uri'] = uri\n",
    "            processed_data.loc[i, 'artist_name'] = track['artists'][0]['name']\n",
    "            processed_data.loc[i, 'track_name'] = track['name']\n",
    "            print(i)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {uri}: {e}\")\n",
    "    return processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 10\n",
    "csv_file = \"mini_df.csv\"  # Path to input CSV file\n",
    "output_file = \"mini_test.csv\"  # Path to save the processed data\n",
    "\n",
    "start_row = 46244 # Adjust row number from which processing needs to be started\n",
    "\n",
    "# Read the CSV file in batches and process each batch\n",
    "for chunk in pd.read_csv(csv_file, chunksize=chunk_size, skiprows=range(1, start_row)):\n",
    "    time.sleep(5)\n",
    "    processed_chunk = process_batch(chunk)\n",
    "    # Append each processed chunk to the output file\n",
    "    processed_chunk.to_csv(output_file, mode=\"a\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading dataset & assigning column names\n",
    "df1 = pd.read_csv('mini_test.csv', header=None)\n",
    "df1.columns = ['track_uri', 'artist_name', 'track_name']\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1[df1.duplicated(keep=False)]\n",
    "df1_unique = df1.drop_duplicates(keep='first')\n",
    "df1_unique.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = ['df1', 'df2']\n",
    "\n",
    "#data2 = [pd.read_csv(f) for f in data1]\n",
    "spotify_data1 = pd.concat([df1, df2], ignore_index=True)\n",
    "spotify_data1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify_data = spotify_data1.drop_duplicates(keep='first')\n",
    "#spotify_data.shape\n",
    "spotify_data.to_csv('spotify_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing on Genius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "spotify_data = pd.read_csv('/Users/rishabhhasija/Documents/neuefische/sentify_recommender/clean_spotify_data.csv', index_col=None)\n",
    "df = spotify_data.iloc[43999:]\n",
    "df = df.reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling for Genius API credentials from dotenv file\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import lyricsgenius\n",
    "import pandas as pd\n",
    "\n",
    "load_dotenv()\n",
    "token = os.getenv(\"genius_token\")\n",
    "genius = lyricsgenius.Genius(token) # Providing token info to access information \n",
    "genius.remove_section_headers = True # Remove section headers (e.g. [Chorus]) from lyrics when searching\n",
    "genius.timeout = 60 # Timeout call for API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lyricsgenius\n",
    "import time\n",
    "\n",
    "genius = lyricsgenius.Genius('your_genius_api_token')\n",
    "genius.remove_section_headers = True\n",
    "\n",
    "# Defining the batches at which to save progress\n",
    "batch_size = 10\n",
    "num_songs = len(df)\n",
    "\n",
    "# Specify the starting index from where to resume processing\n",
    "start_index = int(input(\"input value here\"))\n",
    "\n",
    "for i in range(start_index, num_songs, batch_size):\n",
    "    end_index = min(i + batch_size, num_songs)\n",
    "\n",
    "    for j in range(i, end_index):\n",
    "        try:\n",
    "            song = genius.search_song(df.loc[j, 'track_name'], df.loc[j, 'artist_name'])\n",
    "            df.loc[j, 'lyrics'] = song.lyrics.replace('\\n', ' ') if song else 'Lyrics not found'\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching lyrics for index {j}: {e}\")\n",
    "            df.loc[j, 'lyrics'] = 'Error fetching lyrics'\n",
    "\n",
    "    # Save the DataFrame at regular intervals\n",
    "    df.to_csv('lyrics_rishabh.csv', index=False)\n",
    "    print(f\"Progress saved up to index {end_index - 1}\")\n",
    "\n",
    "    #time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import lyricsgenius\n",
    "import os\n",
    "\n",
    "# Initialize the Genius API\n",
    "genius = lyricsgenius.Genius('g6Ycf22ZvPBoLt_IARCcp8_DUVzU0EHrGdgOKV_v9yqFutnG2F3HBoR1UJcoFDal')\n",
    "genius.remove_section_headers = True\n",
    "\n",
    "# Load your data\n",
    "# Assuming 'original_data.csv' is your dataset that needs lyrics fetching\n",
    "if os.path.exists('lyrics_rishabh.csv'):\n",
    "    df = pd.read_csv('lyrics_rishabh.csv')\n",
    "else:\n",
    "    df = pd.read_csv('original_data.csv')\n",
    "\n",
    "# Define batch size\n",
    "batch_size = 10\n",
    "num_songs = len(df)\n",
    "\n",
    "# Process in batches\n",
    "for i in range(0, num_songs, batch_size):\n",
    "    end_index = min(i + batch_size, num_songs)\n",
    "\n",
    "    for j in range(i, end_index):\n",
    "        # Fetch lyrics only if they are not already present\n",
    "        if pd.isna(df.loc[j, 'lyrics']) or df.loc[j, 'lyrics'] in ['Lyrics not found', 'Error fetching lyrics']:\n",
    "            try:\n",
    "                song = genius.search_song(df.loc[j, 'track_name'], df.loc[j, 'artist_name'])\n",
    "                df.loc[j, 'lyrics'] = song.lyrics.replace('\\n', ' ') if song else 'Lyrics not found'\n",
    "            except Exception as e:\n",
    "                print(f\"Error fetching lyrics for index {j}: {e}\")\n",
    "                df.loc[j, 'lyrics'] = 'Error fetching lyrics'\n",
    "\n",
    "    # Save the DataFrame at regular intervals\n",
    "    df.to_csv('lyrics_rishabh.csv', index=False)\n",
    "    print(f\"Progress saved up to index {end_index - 1}\")\n",
    "\n",
    "# Ensure the final save after completion\n",
    "df.to_csv('lyrics_rishabh.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(spotify_data)-1):\n",
    "    song = genius.search_song(spotify_data['track_name'][i], spotify_data['artist_name'][i])\n",
    "    spotify_data.loc[i, 'lyrics'] = song.lyrics if song else 'Lyrics not found'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fetch artist name and track name\n",
    "def fetch_tracks_details(track_uris):\n",
    "    try:\n",
    "        tracks_info = sp.tracks(track_uris)\n",
    "        results = []\n",
    "        for track in tracks_info['tracks']:\n",
    "            if track:  # Check if track details are successfully retrieved\n",
    "                artist_name = track['artists'][0]['name'] if track['artists'] else 'Unknown'\n",
    "                track_name = track['name'] if track else 'Unknown'\n",
    "                results.append((artist_name, track_name))\n",
    "            else:\n",
    "                results.append(('Unknown', 'Unknown'))\n",
    "        return results\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing batch: {str(e)}\")\n",
    "        return [('Unknown', 'Unknown')] * len(track_uris)\n",
    "\n",
    "# Apply batch processing\n",
    "batch_size = 50\n",
    "artist_names = []\n",
    "track_names = []\n",
    "\n",
    "for i in range(0, len(df_lyrics['track_uri']), batch_size):\n",
    "    batch_uris = df_lyrics['track_uri'][i:i + batch_size].tolist()\n",
    "    batch_results = fetch_tracks_details(batch_uris)\n",
    "    artist_names.extend([res[0] for res in batch_results])\n",
    "    track_names.extend([res[1] for res in batch_results])\n",
    "\n",
    "df_lyrics['alb_name'] = artist_names\n",
    "df_lyrics['trk_name'] = track_names\n",
    "\n",
    "# Save the updated DataFrame\n",
    "df_lyrics.to_csv('df_lyrics_updated.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting File into multiple files of fixed row size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_per_file = 3000  # Number of rows per file\n",
    "\n",
    "# Calculate how many files will be needed\n",
    "num_files = len(df_lyrics) // rows_per_file + (1 if len(df_lyrics) % rows_per_file != 0 else 0)\n",
    "\n",
    "# Split and save the DataFrame into multiple CSV files\n",
    "for i in range(num_files):\n",
    "    start_row = i * rows_per_file\n",
    "    end_row = start_row + rows_per_file\n",
    "    # Create a new CSV file for each chunk\n",
    "    df_lyrics[start_row:end_row].to_csv(f'output_file_{i + 1}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fetching Lyrics from Genius API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import lyricsgenius\n",
    "\n",
    "load_dotenv()\n",
    "token = os.getenv(\"genius_token\")\n",
    "genius = lyricsgenius.Genius(token)\n",
    "genius.remove_section_headers = True # Remove section headers from lyrics when searching\n",
    "genius.timeout = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching lyrics via API\n",
    "for i in range(len(df_lyrics)-66233):\n",
    "    df_lyrics.loc[i, 'lyrics'] = genius.search_song(df_lyrics['track_name'][i], df_lyrics['artist_name'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df_lyrics)-1):\n",
    "    song = genius.search_song(df_lyrics['track_name'][i], df_lyrics['artist_name'][i])\n",
    "    df_lyrics.loc[i, 'lyrics'] = song.lyrics if song else 'Lyrics not found'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lyrics['lyrics'][7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"131 ContributorsTranslationsEspañolFrançaisItalianoPortuguêsTeam Lyrics\\nWait till you're announced\\nWe've not yet lost all our graces\\nThe hounds will stay in chains\\nLook upon Your Greatness and she'll\\nSend the call out, send the call out\\nSend the call out, send the call out\\nSend the call out, send the call out\\nSend the call out, send the call out\\nSend the call out, send the call out\\nSend the call out, send the call out\\nSend the call out, send the call out\\nSend the call out, send the call out\\n\\nCall all the ladies out\\nThey're in their finery\\nA hundred jewels on throats\\nA hundred jewels between teeth\\nNow bring my boys in\\nTheir skin in craters like the moon\\nThe moon we love like a brother\\nWhile he glows through the room\\n\\nDancin' around the lies we tell\\nDancin' around big eyes, as well\\nEven the comatose\\nThey don't dance and tell\\nYou might also like\\nWe live in cities you'll never see on-screen\\nNot very pretty, but we sure know how to run things\\nLivin' in ruins of a palace within my dreams\\nAnd you know, we're on each other's team\\n\\nI'm kind of over gettin' told to throw my hands up in the air\\nSo there\\n\\nSo all the cups got broke\\nShards beneath our feet\\nBut it wasn't my fault\\nAnd everyone's competing\\nFor a love they won't receive\\n'Cause what this palace wants is release\\n\\nWe live in cities you'll never see on-screen\\nNot very pretty, but we sure know how to run things\\nLivin' in ruins of a palace within my dreams\\nAnd you know, we're on each other's team\\n\\nI'm kind of over gettin' told to throw my hands up in the air\\nSo there\\nI'm kind of older than I was when I reveled without a care\\nSo there\\nWe live in cities you'll never see on-screen\\nNot very pretty, but we sure know how to run things\\nLivin' in ruins of a palace within my dreams\\nAnd you know, we're on each other's team\\n\\nWe're on each other's team\\nAnd you know, we're on each other's team\\nWe're on each other's team\\nAnd you know, and you know, and you know330Embed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lyrics['lyrics'].isna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lyricsgenius\n",
    "\n",
    "# Initialize Genius API\n",
    "genius = lyricsgenius.Genius('put_your_token_here')\n",
    "\n",
    "genius.remove_section_headers = True\n",
    "\n",
    "# Spotify Global Top 50 playlist ID\n",
    "playlist_id = '37i9dQZEVXbMDoHDwVN2tF'  # Example ID, update as necessary\n",
    "\n",
    "results = sp.playlist_tracks(playlist_id)\n",
    "tracks_data = []\n",
    "\n",
    "# Fetch track details from Spotify\n",
    "for item in results['items']:\n",
    "    track = item['track']\n",
    "    track_info = {\n",
    "        'Name': track['name'],\n",
    "        'Artist': track['artists'][0]['name'] if track['artists'] else 'Unknown',\n",
    "        'Album': track['album']['name'] if track['album'] else 'Unknown',\n",
    "        'Release Date': track['album']['release_date'] if track['album'] else 'Unknown',\n",
    "        'Popularity': track['popularity']\n",
    "    }\n",
    "    # Fetch lyrics using Genius\n",
    "    song = genius.search_song(track_info['Name'], track_info['Artist'])\n",
    "    track_info['Lyrics'] = song.lyrics if song else 'Lyrics not found'\n",
    "    \n",
    "    tracks_data.append(track_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the lyrics column if it doesn't exist\n",
    "if 'lyrics' not in df_lyrics.columns:\n",
    "    df_lyrics['lyrics'] = None\n",
    "\n",
    "# Defining batch size for progress tracking\n",
    "batch_size = 100\n",
    "num_batches = (len(df_lyrics) + batch_size - 1) // batch_size  # Calculate total number of batches\n",
    "\n",
    "# Processing each song in df_lyrics\n",
    "for i in range(len(df_lyrics)):\n",
    "    if pd.isna(df_lyrics.at[i, 'lyrics']):  # Check if lyrics already fetched to avoid refetching\n",
    "        try:\n",
    "            song = genius.search_song(df_lyrics.at[i, 'track_name'], df_lyrics.at[i, 'artist_name'])\n",
    "            df_lyrics.at[i, 'lyrics'] = song.lyrics if song else 'Lyrics not found'\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching lyrics for row {i}: {e}\")\n",
    "            df_lyrics.at[i, 'lyrics'] = 'Error fetching lyrics'\n",
    "    # Checking print progress\n",
    "    if i % batch_size == 0 or i == len(df_lyrics) - 1:\n",
    "        print(f\"Processed {i+1}/{len(df_lyrics)} songs, Batch {i // batch_size + 1}/{num_batches}\")\n",
    "\n",
    "# Saving complete DataFrame with lyrics to a new file\n",
    "df_lyrics.to_csv('df_final.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save DataFrame to CSV file\n",
    "df_lyrics.to_csv('spotify_lyrics.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lyrics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''import pandas as pd\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "\n",
    "# Initialize spotipy with Spotify API credentials\n",
    "client_id = '5093ad0ad45f435ca7ce43b2afd406b9'  # Replace with your client ID\n",
    "client_secret = 'f151962f414144aa85494be81ccd8e20'  # Replace with your client secret\n",
    "client_credentials_manager = SpotifyClientCredentials(client_id=client_id, client_secret=client_secret)\n",
    "sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)'''\n",
    "\n",
    "# Function to fetch artist name and track name\n",
    "def fetch_tracks_details(track_uris):\n",
    "    try:\n",
    "        tracks_info = sp.tracks(track_uris)\n",
    "        results = []\n",
    "        for track in tracks_info['tracks']:\n",
    "            if track:  # Check if track details are successfully retrieved\n",
    "                artist_name = track['artists'][0]['name'] if track['artists'] else 'Unknown'\n",
    "                track_name = track['name'] if track else 'Unknown'\n",
    "                results.append((artist_name, track_name))\n",
    "            else:\n",
    "                results.append(('Unknown', 'Unknown'))\n",
    "        return results\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing batch: {str(e)}\")\n",
    "        return [('Unknown', 'Unknown')] * len(track_uris)\n",
    "\n",
    "# Apply batch processing\n",
    "batch_size = 50\n",
    "artist_names = []\n",
    "track_names = []\n",
    "\n",
    "for i in range(0, len(df_lyrics['track_uri']), batch_size):\n",
    "    batch_uris = df_lyrics['track_uri'][i:i + batch_size].tolist()\n",
    "    batch_results = fetch_tracks_details(batch_uris)\n",
    "    artist_names.extend([res[0] for res in batch_results])\n",
    "    track_names.extend([res[1] for res in batch_results])\n",
    "\n",
    "df_lyrics['alb_name'] = artist_names\n",
    "df_lyrics['trk_name'] = track_names\n",
    "\n",
    "# Save the updated DataFrame\n",
    "df_lyrics.to_csv('df_lyrics_updated.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Cosine Similarity for Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spotify_features = df_spotify.drop(columns=['playlist_name', 'playlist_num_tracks', 'artist_name', 'track_name', 'album_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "from chunkdot import CosineSimilarityTopK\n",
    "\n",
    "numeric_features = ['playlist_pid', 'track_pos', 'duration_ms']\n",
    "categorical_features = ['track_uri', 'artist_uri', 'album_uri']\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[(\"scaler\", StandardScaler())])\n",
    "categorical_transformer = Pipeline(steps=[(\"encoder\", OneHotEncoder())])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "cos_sim = CosineSimilarityTopK(top_k=50)\n",
    "\n",
    "pipe = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"cos_sim\", cos_sim)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;scaler&#x27;,\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  [&#x27;playlist_pid&#x27;, &#x27;track_pos&#x27;,\n",
       "                                                   &#x27;duration_ms&#x27;]),\n",
       "                                                 (&#x27;cat&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;encoder&#x27;,\n",
       "                                                                   OneHotEncoder())]),\n",
       "                                                  [&#x27;track_uri&#x27;, &#x27;artist_uri&#x27;,\n",
       "                                                   &#x27;album_uri&#x27;])])),\n",
       "                (&#x27;cos_sim&#x27;, CosineSimilarityTopK(top_k=50))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;scaler&#x27;,\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  [&#x27;playlist_pid&#x27;, &#x27;track_pos&#x27;,\n",
       "                                                   &#x27;duration_ms&#x27;]),\n",
       "                                                 (&#x27;cat&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;encoder&#x27;,\n",
       "                                                                   OneHotEncoder())]),\n",
       "                                                  [&#x27;track_uri&#x27;, &#x27;artist_uri&#x27;,\n",
       "                                                   &#x27;album_uri&#x27;])])),\n",
       "                (&#x27;cos_sim&#x27;, CosineSimilarityTopK(top_k=50))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler())]),\n",
       "                                 [&#x27;playlist_pid&#x27;, &#x27;track_pos&#x27;, &#x27;duration_ms&#x27;]),\n",
       "                                (&#x27;cat&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;encoder&#x27;, OneHotEncoder())]),\n",
       "                                 [&#x27;track_uri&#x27;, &#x27;artist_uri&#x27;, &#x27;album_uri&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">num</label><div class=\"sk-toggleable__content\"><pre>[&#x27;playlist_pid&#x27;, &#x27;track_pos&#x27;, &#x27;duration_ms&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">cat</label><div class=\"sk-toggleable__content\"><pre>[&#x27;track_uri&#x27;, &#x27;artist_uri&#x27;, &#x27;album_uri&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder()</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CosineSimilarityTopK</label><div class=\"sk-toggleable__content\"><pre>CosineSimilarityTopK(top_k=50)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('num',\n",
       "                                                  Pipeline(steps=[('scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  ['playlist_pid', 'track_pos',\n",
       "                                                   'duration_ms']),\n",
       "                                                 ('cat',\n",
       "                                                  Pipeline(steps=[('encoder',\n",
       "                                                                   OneHotEncoder())]),\n",
       "                                                  ['track_uri', 'artist_uri',\n",
       "                                                   'album_uri'])])),\n",
       "                ('cos_sim', CosineSimilarityTopK(top_k=50))])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pipe.fit_transform(df_spotify_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>playlist_name</th>\n",
       "      <th>playlist_pid</th>\n",
       "      <th>playlist_num_tracks</th>\n",
       "      <th>track_pos</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>track_uri</th>\n",
       "      <th>artist_uri</th>\n",
       "      <th>track_name</th>\n",
       "      <th>album_uri</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>album_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Party</td>\n",
       "      <td>1000000</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>AronChupa</td>\n",
       "      <td>spotify:track:66U0ASk1VHZsqIkpMjKX3B</td>\n",
       "      <td>spotify:artist:5vCOdeiQt9LyzdI87kt5Sh</td>\n",
       "      <td>Little Swing</td>\n",
       "      <td>spotify:album:4S5MLjwRSi0NJ5nikflYnZ</td>\n",
       "      <td>163809</td>\n",
       "      <td>Little Swing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Party</td>\n",
       "      <td>1000000</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>AronChupa</td>\n",
       "      <td>spotify:track:5MhsZlmKJG6X5kTHkdwC4B</td>\n",
       "      <td>spotify:artist:5vCOdeiQt9LyzdI87kt5Sh</td>\n",
       "      <td>I'm an Albatraoz</td>\n",
       "      <td>spotify:album:1qHVYbxQ6IS8YRviorKDJI</td>\n",
       "      <td>166848</td>\n",
       "      <td>I'm an Albatraoz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Party</td>\n",
       "      <td>1000000</td>\n",
       "      <td>75</td>\n",
       "      <td>2</td>\n",
       "      <td>Lorde</td>\n",
       "      <td>spotify:track:0GZoB8h0kqXn7XFm4Sj06k</td>\n",
       "      <td>spotify:artist:163tK9Wjr9P9DmM0AVK7lm</td>\n",
       "      <td>Yellow Flicker Beat - From The Hunger Games: M...</td>\n",
       "      <td>spotify:album:4UEPxQx0cTcYNsE0n32MHV</td>\n",
       "      <td>232506</td>\n",
       "      <td>Yellow Flicker Beat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Party</td>\n",
       "      <td>1000000</td>\n",
       "      <td>75</td>\n",
       "      <td>3</td>\n",
       "      <td>Lorde</td>\n",
       "      <td>spotify:track:35kahykNu00FPysz3C2euR</td>\n",
       "      <td>spotify:artist:163tK9Wjr9P9DmM0AVK7lm</td>\n",
       "      <td>White Teeth Teens</td>\n",
       "      <td>spotify:album:0rmhjUgoVa17LZuS8xWQ3v</td>\n",
       "      <td>216600</td>\n",
       "      <td>Pure Heroine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Party</td>\n",
       "      <td>1000000</td>\n",
       "      <td>75</td>\n",
       "      <td>4</td>\n",
       "      <td>Lorde</td>\n",
       "      <td>spotify:track:3G6hD9B2ZHOsgf4WfNu7X1</td>\n",
       "      <td>spotify:artist:163tK9Wjr9P9DmM0AVK7lm</td>\n",
       "      <td>Team</td>\n",
       "      <td>spotify:album:0rmhjUgoVa17LZuS8xWQ3v</td>\n",
       "      <td>193058</td>\n",
       "      <td>Pure Heroine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280995</th>\n",
       "      <td>Playlist 2015</td>\n",
       "      <td>1006767</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>El Gran Combo De Puerto Rico</td>\n",
       "      <td>spotify:track:38griAVM808crjbFp9gcPD</td>\n",
       "      <td>spotify:artist:6nnspeopmJAG07xOxHmqTu</td>\n",
       "      <td>Y No Hago Mas Na' - Reggaeton Mix</td>\n",
       "      <td>spotify:album:2QeEEn8jNy5SFx9coIzS3Z</td>\n",
       "      <td>339573</td>\n",
       "      <td>Salsa Classics Revisited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280996</th>\n",
       "      <td>Workout</td>\n",
       "      <td>1006771</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>2Pac</td>\n",
       "      <td>spotify:track:1JClFT74TYSXlzpagbmj0S</td>\n",
       "      <td>spotify:artist:1ZwdS5xdxEREPySFridCfh</td>\n",
       "      <td>California Love - Original Version</td>\n",
       "      <td>spotify:album:3PO9OtQdvCDJN8zDLtZiYd</td>\n",
       "      <td>285026</td>\n",
       "      <td>Greatest Hits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280997</th>\n",
       "      <td>Girlz</td>\n",
       "      <td>1006773</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>Ashley DuBose</td>\n",
       "      <td>spotify:track:4InLm5a9Qtkru6YxEjM4Qc</td>\n",
       "      <td>spotify:artist:2Y9lO01ABSO8OkBU8FI1mp</td>\n",
       "      <td>Intoxicated</td>\n",
       "      <td>spotify:album:5NjFyeZJkYAh5ri9eh8ZSO</td>\n",
       "      <td>279322</td>\n",
       "      <td>Be You</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280998</th>\n",
       "      <td>let's get lost</td>\n",
       "      <td>1006775</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>blackbear</td>\n",
       "      <td>spotify:track:4hdog9vyyqG9pcppG2Izek</td>\n",
       "      <td>spotify:artist:2cFrymmkijnjDg9SS92EPM</td>\n",
       "      <td>90210 (feat. G-Eazy)</td>\n",
       "      <td>spotify:album:1TkwzY3l4LqAfrQwBAx45Q</td>\n",
       "      <td>223295</td>\n",
       "      <td>Deadroses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280999</th>\n",
       "      <td>Mama</td>\n",
       "      <td>1006778</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>Jonas Blue</td>\n",
       "      <td>spotify:track:0NiXXAI876aGImAd6rTj8w</td>\n",
       "      <td>spotify:artist:1HBjj22wzbscIZ9sEb5dyf</td>\n",
       "      <td>Mama</td>\n",
       "      <td>spotify:album:0zMLyv1kNV2B0LDGEK2RbB</td>\n",
       "      <td>181614</td>\n",
       "      <td>Jonas Blue: Electronic Nature - The Mix 2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>281000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         playlist_name  playlist_pid  playlist_num_tracks  track_pos   \n",
       "0                Party       1000000                   75          0  \\\n",
       "1                Party       1000000                   75          1   \n",
       "2                Party       1000000                   75          2   \n",
       "3                Party       1000000                   75          3   \n",
       "4                Party       1000000                   75          4   \n",
       "...                ...           ...                  ...        ...   \n",
       "280995   Playlist 2015       1006767                   21          0   \n",
       "280996         Workout       1006771                   25          0   \n",
       "280997           Girlz       1006773                   17          0   \n",
       "280998  let's get lost       1006775                   36          0   \n",
       "280999            Mama       1006778                   29          0   \n",
       "\n",
       "                         artist_name                             track_uri   \n",
       "0                          AronChupa  spotify:track:66U0ASk1VHZsqIkpMjKX3B  \\\n",
       "1                          AronChupa  spotify:track:5MhsZlmKJG6X5kTHkdwC4B   \n",
       "2                              Lorde  spotify:track:0GZoB8h0kqXn7XFm4Sj06k   \n",
       "3                              Lorde  spotify:track:35kahykNu00FPysz3C2euR   \n",
       "4                              Lorde  spotify:track:3G6hD9B2ZHOsgf4WfNu7X1   \n",
       "...                              ...                                   ...   \n",
       "280995  El Gran Combo De Puerto Rico  spotify:track:38griAVM808crjbFp9gcPD   \n",
       "280996                          2Pac  spotify:track:1JClFT74TYSXlzpagbmj0S   \n",
       "280997                 Ashley DuBose  spotify:track:4InLm5a9Qtkru6YxEjM4Qc   \n",
       "280998                     blackbear  spotify:track:4hdog9vyyqG9pcppG2Izek   \n",
       "280999                    Jonas Blue  spotify:track:0NiXXAI876aGImAd6rTj8w   \n",
       "\n",
       "                                   artist_uri   \n",
       "0       spotify:artist:5vCOdeiQt9LyzdI87kt5Sh  \\\n",
       "1       spotify:artist:5vCOdeiQt9LyzdI87kt5Sh   \n",
       "2       spotify:artist:163tK9Wjr9P9DmM0AVK7lm   \n",
       "3       spotify:artist:163tK9Wjr9P9DmM0AVK7lm   \n",
       "4       spotify:artist:163tK9Wjr9P9DmM0AVK7lm   \n",
       "...                                       ...   \n",
       "280995  spotify:artist:6nnspeopmJAG07xOxHmqTu   \n",
       "280996  spotify:artist:1ZwdS5xdxEREPySFridCfh   \n",
       "280997  spotify:artist:2Y9lO01ABSO8OkBU8FI1mp   \n",
       "280998  spotify:artist:2cFrymmkijnjDg9SS92EPM   \n",
       "280999  spotify:artist:1HBjj22wzbscIZ9sEb5dyf   \n",
       "\n",
       "                                               track_name   \n",
       "0                                            Little Swing  \\\n",
       "1                                        I'm an Albatraoz   \n",
       "2       Yellow Flicker Beat - From The Hunger Games: M...   \n",
       "3                                       White Teeth Teens   \n",
       "4                                                    Team   \n",
       "...                                                   ...   \n",
       "280995                  Y No Hago Mas Na' - Reggaeton Mix   \n",
       "280996                 California Love - Original Version   \n",
       "280997                                        Intoxicated   \n",
       "280998                               90210 (feat. G-Eazy)   \n",
       "280999                                               Mama   \n",
       "\n",
       "                                   album_uri  duration_ms   \n",
       "0       spotify:album:4S5MLjwRSi0NJ5nikflYnZ       163809  \\\n",
       "1       spotify:album:1qHVYbxQ6IS8YRviorKDJI       166848   \n",
       "2       spotify:album:4UEPxQx0cTcYNsE0n32MHV       232506   \n",
       "3       spotify:album:0rmhjUgoVa17LZuS8xWQ3v       216600   \n",
       "4       spotify:album:0rmhjUgoVa17LZuS8xWQ3v       193058   \n",
       "...                                      ...          ...   \n",
       "280995  spotify:album:2QeEEn8jNy5SFx9coIzS3Z       339573   \n",
       "280996  spotify:album:3PO9OtQdvCDJN8zDLtZiYd       285026   \n",
       "280997  spotify:album:5NjFyeZJkYAh5ri9eh8ZSO       279322   \n",
       "280998  spotify:album:1TkwzY3l4LqAfrQwBAx45Q       223295   \n",
       "280999  spotify:album:0zMLyv1kNV2B0LDGEK2RbB       181614   \n",
       "\n",
       "                                          album_name  \n",
       "0                                       Little Swing  \n",
       "1                                   I'm an Albatraoz  \n",
       "2                                Yellow Flicker Beat  \n",
       "3                                       Pure Heroine  \n",
       "4                                       Pure Heroine  \n",
       "...                                              ...  \n",
       "280995                      Salsa Classics Revisited  \n",
       "280996                                 Greatest Hits  \n",
       "280997                                        Be You  \n",
       "280998                                     Deadroses  \n",
       "280999  Jonas Blue: Electronic Nature - The Mix 2017  \n",
       "\n",
       "[281000 rows x 11 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test)\n",
    "# Convert csr.matrix to Dataframe\n",
    "test_df = pd.DataFrame.sparse.from_spmatrix(test)\n",
    "df_spotify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(281000, 281000)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build index with Track names\n",
    "track_uri = df_spotify['track_uri']\n",
    "indices = pd.Series(df_spotify.index, index=df_spotify['track_uri'])\n",
    "\n",
    "# Function that get Track recommendations based on the cosine similarity \n",
    "def track_recommendations(track):\n",
    "    #get the index of the Track we put into the function\n",
    "    idx = indices[track]\n",
    "    #calculate all cosine similarities to that Track and store it in a list\n",
    "    sim_scores = list(enumerate(test_df[idx]))\n",
    "    #sort the list staring with the highest similarity\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    #get the similarities from 1:11 (not starting with 0 because it is the same Track)\n",
    "    sim_scores = sim_scores[1:11]\n",
    "    #get the indices of that 10 Track\n",
    "    track_indices = [i[0] for i in sim_scores]\n",
    "    #return the Track names of that 10 Track\n",
    "    return track_uri.iloc[track_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66    spotify:track:71eRCfoq3g4qeLNcR75Hig\n",
       "65    spotify:track:38YgZVHPWOWsKrsCXz6JyP\n",
       "64    spotify:track:5xS9hkTGfxqXyxX6wWWTt4\n",
       "63    spotify:track:2Pr1nZpt8A8WP7QYpyq6L3\n",
       "62    spotify:track:5MxNLUsfh7uzROypsoO5qe\n",
       "61    spotify:track:3YU9X8ryOR20beT7wOlDIJ\n",
       "60    spotify:track:0QXaOq4DrPkX7cJsXhERrE\n",
       "59    spotify:track:6EpRaXYhGOB3fj4V2uDkMJ\n",
       "58    spotify:track:2ekn2ttSfGqwhhate0LSR0\n",
       "57    spotify:track:7F9vK8hNFMml4GtHsaXui6\n",
       "Name: track_uri, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "track_recommendations('spotify:track:1JClFT74TYSXlzpagbmj0S')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
