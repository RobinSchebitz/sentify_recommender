{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working on Spotify Playlist\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing libraries and setting up authentication with Spotify API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing data from Spotify dataset\n",
    "\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyOAuth\n",
    "\n",
    "# Replace 'your_client_id', 'your_client_secret', and 'your_redirect_uri' with your actual values\n",
    "sp = spotipy.Spotify(auth_manager=SpotifyOAuth(\n",
    "    client_id='5093ad0ad45f435ca7ce43b2afd406b9',\n",
    "    client_secret='f151962f414144aa85494be81ccd8e20',\n",
    "    redirect_uri='http://localhost:8888/callback',\n",
    "    scope=\"user-library-read playlist-read-private\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetching data from Spotify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''playlist_id = '6JOysTE0drK9yDi1Xs4FKy'  # Replace with the actual playlist ID\n",
    "playlist = sp.playlist(playlist_id)\n",
    "print(playlist['name'])\n",
    "for item in playlist['tracks']['items']:\n",
    "    track = item['track']\n",
    "    print(track['name'], '-', track['artists'][0]['name'])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Fetch saved tracks\n",
    "playlist_id = '6JOysTE0drK9yDi1Xs4FKy'\n",
    "\n",
    "results = sp.playlist_tracks(playlist_id)\n",
    "tracks_data = {\n",
    "    'Name': [],\n",
    "    'Artist': [],\n",
    "    'Album': [],\n",
    "    'Release Date': []\n",
    "}\n",
    "\n",
    "for item in results['items']:\n",
    "    track = item.get('track')\n",
    "    if track:  # Check if track details are present\n",
    "        name = track.get('name', 'No Title Available')\n",
    "        artist_name = track['artists'][0].get('name', 'No Artist Available') if track['artists'] else 'No Artists'\n",
    "        album_name = track['album'].get('name', 'No Album Available') if track['album'] else 'No Album'\n",
    "        release_date = track['album'].get('release_date', 'No Release Date Available') if track['album'] else 'No Release Info'\n",
    "        \n",
    "        tracks_data['Name'].append(name)\n",
    "        tracks_data['Artist'].append(artist_name)\n",
    "        tracks_data['Album'].append(album_name)\n",
    "        tracks_data['Release Date'].append(release_date)\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_tracks = pd.DataFrame(tracks_data)\n",
    "print(df_tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyOAuth\n",
    "\n",
    "# Initialize the Spotify client\n",
    "sp = spotipy.Spotify(auth_manager=SpotifyOAuth(\n",
    "    client_id='your_client_id',\n",
    "    client_secret='your_client_secret',\n",
    "    redirect_uri='http://localhost:8888/callback',\n",
    "    scope='user-library-read'))\n",
    "\n",
    "# Search for tracks by genre\n",
    "genre = \"rock\"  # Example genre\n",
    "results = sp.search(q='genre:' + genre, type='track', limit=50)\n",
    "tracks_data = {\n",
    "    'Name': [],\n",
    "    'Artist': [],\n",
    "    'Genre': genre,\n",
    "    'Popularity': []\n",
    "}\n",
    "\n",
    "for track in results['tracks']['items']:\n",
    "    tracks_data['Name'].append(track['name'])\n",
    "    tracks_data['Artist'].append(track['artists'][0]['name'])\n",
    "    tracks_data['Popularity'].append(track['popularity'])\n",
    "\n",
    "# Print or process the results\n",
    "print([tracks_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing Song Data with Lyrics using Genius API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lyricsgenius\n",
    "\n",
    "# Initialize Genius API\n",
    "genius = lyricsgenius.Genius('put_your_token_here')\n",
    "\n",
    "genius.remove_section_headers = True\n",
    "\n",
    "# Spotify Global Top 50 playlist ID\n",
    "playlist_id = '37i9dQZEVXbMDoHDwVN2tF'  # Example ID, update as necessary\n",
    "\n",
    "results = sp.playlist_tracks(playlist_id)\n",
    "tracks_data = []\n",
    "\n",
    "# Fetch track details from Spotify\n",
    "for item in results['items']:\n",
    "    track = item['track']\n",
    "    track_info = {\n",
    "        'Name': track['name'],\n",
    "        'Artist': track['artists'][0]['name'] if track['artists'] else 'Unknown',\n",
    "        'Album': track['album']['name'] if track['album'] else 'Unknown',\n",
    "        'Release Date': track['album']['release_date'] if track['album'] else 'Unknown',\n",
    "        'Popularity': track['popularity']\n",
    "    }\n",
    "    # Fetch lyrics using Genius\n",
    "    song = genius.search_song(track_info['Name'], track_info['Artist'])\n",
    "    track_info['Lyrics'] = song.lyrics if song else 'Lyrics not found'\n",
    "    \n",
    "    tracks_data.append(track_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert the data to a pandas DataFrame\n",
    "df_tracks = pd.DataFrame(tracks_data)\n",
    "\n",
    "# Set column names and display the DataFrame\n",
    "df_tracks.columns = ['Track Name', 'Artist', 'Album', 'Release Date', 'Popularity', 'Lyrics']\n",
    "print(df_tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save DataFrame to CSV file\n",
    "df_tracks.to_csv('spotify_songs_with_lyrics.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tracks.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing data\n",
    "\n",
    "Clean the lyrics by removing punctuation, converting to lowercase, and other typical text cleaning steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Removeing punctuation\n",
    "    text = text.lower()  # Convert to lower case\n",
    "    return text\n",
    "\n",
    "# Apply the cleaning function to the lyrics column\n",
    "df_tracks['cleaned_lyrics'] = df_tracks['Lyrics'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize a TF-IDF Vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(df_tracks['cleaned_lyrics'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis using VADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# Initialize the VADER sentiment intensity analyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Function to get the compound sentiment score\n",
    "def get_sentiment(text):\n",
    "    score = analyzer.polarity_scores(text)\n",
    "    return score['compound']  # Return the compound score\n",
    "\n",
    "# Apply the sentiment analysis function to the cleaned lyrics\n",
    "df_tracks['sentiment_score'] = df_tracks['cleaned_lyrics'].apply(get_sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign Sentiment Labels\n",
    "\n",
    "Classifying the sentiments as positive, neutral or negative based on the computed score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_sentiment(score):\n",
    "    if score > 0.05:\n",
    "        return 'positive'\n",
    "    elif score < -0.05:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'\n",
    "\n",
    "# Apply sentiment label assignment\n",
    "df_tracks['sentiment_label'] = df_tracks['sentiment_score'].apply(assign_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_tracks[['Track Name', 'Artist', 'sentiment_score', 'sentiment_label']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tracks[['Track Name', 'Artist', 'sentiment_score', 'sentiment_label']].to_csv('test_sentiment.csv', index=False)\n",
    "\n",
    "test_sentiment = pd.read_csv('test_sentiment.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Json file to Pandas readable format\n",
    "\n",
    "Start by importing spotify challenge (AI Crowd) file into python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load JSON data from file\n",
    "with open('/Users/rishabhhasija/Documents/neuefische/sentify_recommender/data/challenge_set.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Initialize an empty list to collect all track data\n",
    "all_tracks = []\n",
    "\n",
    "# Loop through each playlist in the dataset\n",
    "for playlist in data['playlists']:\n",
    "    for track in playlist['tracks']:\n",
    "        # Add playlist-level information to each track record\n",
    "        track_info = {\n",
    "            'playlist_name': playlist.get('name', 'Unknown'),\n",
    "            'playlist_pid': playlist['pid'],\n",
    "            'playlist_num_tracks': playlist['num_tracks'],\n",
    "            'track_pos': track['pos'],\n",
    "            'artist_name': track['artist_name'],\n",
    "            'track_uri': track['track_uri'],\n",
    "            'artist_uri': track['artist_uri'],\n",
    "            'track_name': track['track_name'],\n",
    "            'album_uri': track['album_uri'],\n",
    "            'duration_ms': track['duration_ms'],\n",
    "            'album_name': track['album_name']\n",
    "        }\n",
    "        all_tracks.append(track_info)\n",
    "\n",
    "# Convert the list of track dictionaries to a DataFrame\n",
    "df_spotify = pd.DataFrame(all_tracks)\n",
    "\n",
    "# Display the first few rows of the DataFrame to verify\n",
    "#print(df_spotify.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(281000, 11)\n"
     ]
    }
   ],
   "source": [
    "print(df_spotify.shape)\n",
    "#print(df_spotify.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['playlist_name', 'playlist_pid', 'playlist_num_tracks', 'track_pos',\n",
       "       'artist_name', 'track_uri', 'artist_uri', 'track_name', 'album_uri',\n",
       "       'duration_ms', 'album_name'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spotify.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spotify['playlist_num_tracks'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_spotify\n",
    "#df_lyrics = df_spotify['track_uri'].unique()  \n",
    "df_lyrics = df_spotify.drop_duplicates(subset=['track_uri']).drop(['playlist_name', 'playlist_pid', 'playlist_num_tracks', 'track_pos', 'artist_name',\n",
    "       'artist_uri', 'track_name', 'album_uri', 'duration_ms', 'album_name'], axis=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66243, 1)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lyrics.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47397, 1)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mini_df = df_lyrics.head(47397)\n",
    "mini_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lyrics.to_csv('df_lyrics.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_df.to_csv('mini_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "import time\n",
    "\n",
    "auth_manager = SpotifyClientCredentials(client_id='59cdbf840d9245118927fc195c3e4e0a', client_secret='f3b0a7237fb04ca2ba9fc6bbefb729b7')\n",
    "sp = spotipy.Spotify(auth_manager=auth_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "#def file_exists_and_not_empty(file_name):\n",
    "#    return os.path.isfile(file_name) and os.stat(file_name).st_size > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_batch(batch_data):\n",
    "    # Creating an empty DataFrame to store updated data\n",
    "    processed_data = pd.DataFrame(columns=['track_uri', 'artist_name', 'track_name'])\n",
    "    \n",
    "    # Iterating over the batch_data to fetch details from Spotify\n",
    "    for i, uri in enumerate(batch_data['track_uri']):\n",
    "        try:\n",
    "            track = sp.track(uri)\n",
    "            processed_data.loc[i, 'track_uri'] = uri\n",
    "            processed_data.loc[i, 'artist_name'] = track['artists'][0]['name']\n",
    "            processed_data.loc[i, 'track_name'] = track['name']\n",
    "            print(i)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {uri}: {e}\")\n",
    "    return processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "chunk_size = 10\n",
    "csv_file = \"mini_df.csv\"  # Path to input CSV file\n",
    "output_file = \"mini_test.csv\"  # Path to save the processed data\n",
    "\n",
    "start_row = 46244 # Adjust row number from which processing needs to be started\n",
    "\n",
    "# Read the CSV file in batches and process each batch\n",
    "for chunk in pd.read_csv(csv_file, chunksize=chunk_size, skiprows=range(1, start_row)):\n",
    "    time.sleep(5)\n",
    "    processed_chunk = process_batch(chunk)\n",
    "    # Append each processed chunk to the output file\n",
    "    processed_chunk.to_csv(output_file, mode=\"a\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_uri</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>track_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spotify:track:66U0ASk1VHZsqIkpMjKX3B</td>\n",
       "      <td>AronChupa</td>\n",
       "      <td>Little Swing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spotify:track:5MhsZlmKJG6X5kTHkdwC4B</td>\n",
       "      <td>AronChupa</td>\n",
       "      <td>I'm an Albatraoz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spotify:track:0GZoB8h0kqXn7XFm4Sj06k</td>\n",
       "      <td>Lorde</td>\n",
       "      <td>Yellow Flicker Beat - From The Hunger Games: M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spotify:track:35kahykNu00FPysz3C2euR</td>\n",
       "      <td>Lorde</td>\n",
       "      <td>White Teeth Teens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spotify:track:3G6hD9B2ZHOsgf4WfNu7X1</td>\n",
       "      <td>Lorde</td>\n",
       "      <td>Team</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              track_uri artist_name   \n",
       "0  spotify:track:66U0ASk1VHZsqIkpMjKX3B   AronChupa  \\\n",
       "1  spotify:track:5MhsZlmKJG6X5kTHkdwC4B   AronChupa   \n",
       "2  spotify:track:0GZoB8h0kqXn7XFm4Sj06k       Lorde   \n",
       "3  spotify:track:35kahykNu00FPysz3C2euR       Lorde   \n",
       "4  spotify:track:3G6hD9B2ZHOsgf4WfNu7X1       Lorde   \n",
       "\n",
       "                                          track_name  \n",
       "0                                       Little Swing  \n",
       "1                                   I'm an Albatraoz  \n",
       "2  Yellow Flicker Beat - From The Hunger Games: M...  \n",
       "3                                  White Teeth Teens  \n",
       "4                                               Team  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading dataset & assigning column names\n",
    "df1 = pd.read_csv('mini_test.csv', header=None)\n",
    "df1.columns = ['track_uri', 'artist_name', 'track_name']\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47387, 3)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df1[df1.duplicated(keep=False)]\n",
    "df1_unique = df1.drop_duplicates(keep='first')\n",
    "df1_unique.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = ['df1', 'df2']\n",
    "\n",
    "#data2 = [pd.read_csv(f) for f in data1]\n",
    "spotify_data1 = pd.concat([df1, df2], ignore_index=True)\n",
    "spotify_data1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify_data = spotify_data1.drop_duplicates(keep='first')\n",
    "#spotify_data.shape\n",
    "spotify_data.to_csv('spotify_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing on Genius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "spotify_data = pd.read_csv('/Users/rishabhhasija/Documents/neuefische/sentify_recommender/spotify_data.csv')\n",
    "#df2 = spotify_data.head(10)\n",
    "#df2.to_csv('df2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling for Genius API credentials from dotenv file\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import lyricsgenius\n",
    "import pandas as pd\n",
    "\n",
    "load_dotenv()\n",
    "token = os.getenv(\"genius_token\")\n",
    "genius = lyricsgenius.Genius(token) # Providing token info to access information \n",
    "genius.remove_section_headers = True # Remove section headers (e.g. [Chorus]) from lyrics when searching\n",
    "genius.timeout = 60 # Timeout call for API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_batch(batch_data):\n",
    "    # Creating an empty DataFrame to store updated data\n",
    "    processed_data = pd.DataFrame(columns=['track_uri', 'artist_name', 'track_name', 'lyrics'])\n",
    "\n",
    "    # Iterating over the batch_data to fetch details from Spotify\n",
    "    for i in range(len(batch_data)-1):\n",
    "        try:\n",
    "            track = genius.search_song(batch_data['track_name'][i], batch_data['artist_name'][i])\n",
    "\n",
    "            processed_data.loc[i, 'track_uri'] = batch_data['track_uri'].iloc[i]\n",
    "            processed_data.loc[i, 'artist_name'] = batch_data['artist_name'].iloc[i]\n",
    "            processed_data.loc[i, 'track_name'] = batch_data['track_name'].iloc[i]\n",
    "            processed_data.loc[i, 'lyrics'] = track.lyrics if track else 'Lyrics not found'\n",
    "\n",
    "            print(i)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {batch_data['track_uri'][i]}: {e}\")\n",
    "    return processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 10\n",
    "csv_file = '/Users/rishabhhasija/Documents/neuefische/sentify_recommender/spotify_data.csv'  # Path to input CSV file\n",
    "output_file = \"lyrics_test.csv\"  # Path to save the processed data\n",
    "\n",
    "#start_row = 0 # Adjust row number from which processing needs to be started\n",
    "pd.DataFrame(columns=['track_uri', 'artist_name', 'track_name', 'lyrics']).to_csv(output_file, index=False)\n",
    "\n",
    "# Read the CSV file in batches and process each batch\n",
    "for chunk in pd.read_csv(csv_file, chunksize=chunk_size):\n",
    "    processed_chunk = process_batch(chunk)\n",
    "    processed_chunk.to_csv(output_file, mode=\"a\", header=False, index=False)\n",
    "    # Append each processed chunk to the output file\n",
    "    print(processed_chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for \"Halloween Spooks\" by Lambert, Hendricks & Ross...\n",
      "Done.\n",
      "Searching for \"Nightmare\" by Artie Shaw...\n",
      "Done.\n",
      "Searching for \"The Ghost of Smoky Joe\" by Cab Calloway & His Orchestra...\n",
      "No results found for: 'The Ghost of Smoky Joe Cab Calloway & His Orchestra'\n",
      "Searching for \"The Little Man Who Wasn't There (feat. Glenn Miller)\" by Glenn Miller...\n",
      "Done.\n",
      "Searching for \"Coleccionista de Canciones\" by Camila...\n",
      "Done.\n",
      "Searching for \"Mientes\" by Camila...\n",
      "Done.\n",
      "Searching for \"Yo Quiero\" by Camila...\n",
      "Done.\n",
      "Searching for \"De Mí\" by Camila...\n",
      "Done.\n",
      "Searching for \"No Veo la Hora\" by Noel Schajris...\n",
      "Done.\n",
      "Searching for \"Don't Lay Your Head\" by Us The Duo...\n",
      "Done.\n",
      "Progress saved up to index 84\n",
      "Searching for \"Come Back\" by Us The Duo...\n",
      "Done.\n",
      "Searching for \"No Matter Where You Are\" by Us The Duo...\n",
      "Done.\n",
      "Searching for \"Poison & Wine\" by The Civil Wars...\n",
      "Done.\n",
      "Searching for \"Hold Back The River\" by James Bay...\n",
      "Error fetching lyrics for index 88: Request timed out:\n",
      "HTTPSConnectionPool(host='genius.com', port=443): Read timed out. (read timeout=5)\n",
      "Searching for \"Once In a While\" by Timeflies...\n",
      "Done.\n",
      "Searching for \"A closeness\" by Dermot Kennedy...\n",
      "Done.\n",
      "Searching for \"7 Years\" by Lukas Graham...\n",
      "Done.\n",
      "Searching for \"The Wolf\" by Eddie Vedder...\n",
      "Done.\n",
      "Searching for \"Heartbeats\" by José González...\n",
      "Done.\n",
      "Searching for \"Creep\" by Radiohead...\n",
      "Error fetching lyrics for index 94: Request timed out:\n",
      "HTTPSConnectionPool(host='genius.com', port=443): Read timed out. (read timeout=5)\n",
      "Progress saved up to index 94\n",
      "Searching for \"Smells Like Teen Spirit\" by Nirvana...\n",
      "Done.\n",
      "Searching for \"Black Hole Sun\" by Soundgarden...\n",
      "Done.\n",
      "Searching for \"Give It Away\" by Red Hot Chili Peppers...\n",
      "Done.\n",
      "Searching for \"What I Got\" by Sublime...\n",
      "Done.\n",
      "Searching for \"T-Shirt\" by Thomas Rhett...\n",
      "Done.\n",
      "Searching for \"Die A Happy Man\" by Thomas Rhett...\n",
      "Done.\n",
      "Searching for \"It Goes Like This\" by Thomas Rhett...\n",
      "Done.\n",
      "Searching for \"My House\" by Flo Rida...\n",
      "Done.\n",
      "Searching for \"Cruise\" by Florida Georgia Line...\n",
      "Done.\n",
      "Searching for \"Fight Song\" by Rachel Platten...\n",
      "Done.\n",
      "Progress saved up to index 104\n",
      "Searching for \"Marvin Gaye (feat. Wale) - Remix\" by Charlie Puth...\n",
      "Done.\n",
      "Searching for \"I Need Your Love (feat. Mohombi, Faydee & Costi)\" by Shaggy...\n",
      "Done.\n",
      "Searching for \"2 Heads\" by Coleman Hell...\n",
      "Done.\n",
      "Searching for \"I Really Like You\" by Carly Rae Jepsen...\n",
      "Done.\n",
      "Searching for \"Despacito - Remix\" by Luis Fonsi...\n",
      "Done.\n",
      "Searching for \"I'm the One (feat. Justin Bieber, Quavo, Chance the Rapper & Lil Wayne)\" by DJ Khaled...\n",
      "Done.\n",
      "Searching for \"Shape of You\" by Ed Sheeran...\n",
      "Done.\n",
      "Searching for \"goosebumps\" by Travis Scott...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(i, end_index):\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 20\u001b[0m         song \u001b[38;5;241m=\u001b[39m \u001b[43mgenius\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch_song\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspotify_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrack_name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspotify_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43martist_name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m         spotify_data\u001b[38;5;241m.\u001b[39mloc[j, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlyrics\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m song\u001b[38;5;241m.\u001b[39mlyrics\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m song \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLyrics not found\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Documents/neuefische/sentify_recommender/.venv/lib/python3.11/site-packages/lyricsgenius/genius.py:436\u001b[0m, in \u001b[0;36mGenius.search_song\u001b[0;34m(self, title, artist, song_id, get_full_info)\u001b[0m\n\u001b[1;32m    432\u001b[0m     song_info\u001b[38;5;241m.\u001b[39mupdate(new_info)\n\u001b[1;32m    434\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (song_info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlyrics_state\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcomplete\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    435\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m song_info\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minstrumental\u001b[39m\u001b[38;5;124m'\u001b[39m)):\n\u001b[0;32m--> 436\u001b[0m     lyrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlyrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43msong_url\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msong_info\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43murl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    438\u001b[0m     lyrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/Documents/neuefische/sentify_recommender/.venv/lib/python3.11/site-packages/lyricsgenius/genius.py:132\u001b[0m, in \u001b[0;36mGenius.lyrics\u001b[0;34m(self, song_id, song_url, remove_section_headers)\u001b[0m\n\u001b[1;32m    128\u001b[0m     path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msong(song_id)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msong\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m    130\u001b[0m \u001b[38;5;66;03m# Scrape the song lyrics from the HTML\u001b[39;00m\n\u001b[1;32m    131\u001b[0m html \u001b[38;5;241m=\u001b[39m BeautifulSoup(\n\u001b[0;32m--> 132\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<br/>\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    134\u001b[0m )\n\u001b[1;32m    136\u001b[0m \u001b[38;5;66;03m# Determine the class of the div\u001b[39;00m\n\u001b[1;32m    137\u001b[0m div \u001b[38;5;241m=\u001b[39m html\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiv\u001b[39m\u001b[38;5;124m\"\u001b[39m, class_\u001b[38;5;241m=\u001b[39mre\u001b[38;5;241m.\u001b[39mcompile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m^lyrics$|Lyrics__Root\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[0;32m~/Documents/neuefische/sentify_recommender/.venv/lib/python3.11/site-packages/lyricsgenius/api/base.py:75\u001b[0m, in \u001b[0;36mSender._make_request\u001b[0;34m(self, path, method, params_, public_api, web, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m tries \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 75\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m                                     \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m     response\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m Timeout \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Documents/neuefische/sentify_recommender/.venv/lib/python3.11/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/Documents/neuefische/sentify_recommender/.venv/lib/python3.11/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/Documents/neuefische/sentify_recommender/.venv/lib/python3.11/site-packages/requests/adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    483\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 486\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[0;32m~/Documents/neuefische/sentify_recommender/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:793\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    790\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    792\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 793\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    803\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    805\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    806\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[1;32m    809\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/neuefische/sentify_recommender/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:537\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 537\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    539\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m~/Documents/neuefische/sentify_recommender/.venv/lib/python3.11/site-packages/urllib3/connection.py:466\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresponse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPResponse\n\u001b[1;32m    465\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 466\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    469\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/http/client.py:1375\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1373\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1374\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1375\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1376\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1377\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/http/client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 318\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/http/client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 279\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mreadline(_MAXLINE \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 706\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    708\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/ssl.py:1278\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1274\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1275\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1276\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1277\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1278\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1279\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1280\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/ssl.py:1134\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1132\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1133\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1134\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1135\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1136\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import lyricsgenius\n",
    "import time\n",
    "\n",
    "genius = lyricsgenius.Genius('your_genius_api_token')\n",
    "genius.remove_section_headers = True\n",
    "\n",
    "# Defining the batches at which to save progress\n",
    "batch_size = 10\n",
    "num_songs = len(spotify_data)\n",
    "\n",
    "# Specify the starting index from where to resume processing\n",
    "start_index = int(input(\"input value here\"))\n",
    "\n",
    "for i in range(start_index, num_songs, batch_size):\n",
    "    end_index = min(i + batch_size, num_songs)\n",
    "\n",
    "    for j in range(i, end_index):\n",
    "        try:\n",
    "            song = genius.search_song(spotify_data.loc[j, 'track_name'], spotify_data.loc[j, 'artist_name'])\n",
    "            spotify_data.loc[j, 'lyrics'] = song.lyrics.replace('\\n', ' ') if song else 'Lyrics not found'\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching lyrics for index {j}: {e}\")\n",
    "            spotify_data.loc[j, 'lyrics'] = 'Error fetching lyrics'\n",
    "\n",
    "    # Save the DataFrame at regular intervals\n",
    "    spotify_data.to_csv('lyrics_rishabh.csv', index=False)\n",
    "    print(f\"Progress saved up to index {end_index - 1}\")\n",
    "\n",
    "    time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(spotify_data)-1):\n",
    "    song = genius.search_song(spotify_data['track_name'][i], spotify_data['artist_name'][i])\n",
    "    spotify_data.loc[i, 'lyrics'] = song.lyrics if song else 'Lyrics not found'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fetch artist name and track name\n",
    "def fetch_tracks_details(track_uris):\n",
    "    try:\n",
    "        tracks_info = sp.tracks(track_uris)\n",
    "        results = []\n",
    "        for track in tracks_info['tracks']:\n",
    "            if track:  # Check if track details are successfully retrieved\n",
    "                artist_name = track['artists'][0]['name'] if track['artists'] else 'Unknown'\n",
    "                track_name = track['name'] if track else 'Unknown'\n",
    "                results.append((artist_name, track_name))\n",
    "            else:\n",
    "                results.append(('Unknown', 'Unknown'))\n",
    "        return results\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing batch: {str(e)}\")\n",
    "        return [('Unknown', 'Unknown')] * len(track_uris)\n",
    "\n",
    "# Apply batch processing\n",
    "batch_size = 50\n",
    "artist_names = []\n",
    "track_names = []\n",
    "\n",
    "for i in range(0, len(df_lyrics['track_uri']), batch_size):\n",
    "    batch_uris = df_lyrics['track_uri'][i:i + batch_size].tolist()\n",
    "    batch_results = fetch_tracks_details(batch_uris)\n",
    "    artist_names.extend([res[0] for res in batch_results])\n",
    "    track_names.extend([res[1] for res in batch_results])\n",
    "\n",
    "df_lyrics['alb_name'] = artist_names\n",
    "df_lyrics['trk_name'] = track_names\n",
    "\n",
    "# Save the updated DataFrame\n",
    "df_lyrics.to_csv('df_lyrics_updated.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_uri</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>track_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spotify:track:66U0ASk1VHZsqIkpMjKX3B</td>\n",
       "      <td>AronChupa</td>\n",
       "      <td>Little Swing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spotify:track:5MhsZlmKJG6X5kTHkdwC4B</td>\n",
       "      <td>AronChupa</td>\n",
       "      <td>I'm an Albatraoz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spotify:track:0GZoB8h0kqXn7XFm4Sj06k</td>\n",
       "      <td>Lorde</td>\n",
       "      <td>Yellow Flicker Beat - From The Hunger Games: M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spotify:track:35kahykNu00FPysz3C2euR</td>\n",
       "      <td>Lorde</td>\n",
       "      <td>White Teeth Teens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spotify:track:3G6hD9B2ZHOsgf4WfNu7X1</td>\n",
       "      <td>Lorde</td>\n",
       "      <td>Team</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spotify:track:6WQLkih8nE0JdUCEyLaGnQ</td>\n",
       "      <td>Alesso</td>\n",
       "      <td>Heroes (we could be)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>spotify:track:37sINbJZcFdHFAsVNsPq1i</td>\n",
       "      <td>The Script</td>\n",
       "      <td>Superheroes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>spotify:track:0yhPEz5KxlDwckGJaMlZqM</td>\n",
       "      <td>Fall Out Boy</td>\n",
       "      <td>Centuries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spotify:track:5j9iuo3tMmQIfnEEQOOjxh</td>\n",
       "      <td>American Authors</td>\n",
       "      <td>Best Day Of My Life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spotify:track:4eLSCSELtKxZwXnFbNLXT5</td>\n",
       "      <td>Imagine Dragons</td>\n",
       "      <td>On Top Of The World</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              track_uri       artist_name   \n",
       "0  spotify:track:66U0ASk1VHZsqIkpMjKX3B         AronChupa  \\\n",
       "1  spotify:track:5MhsZlmKJG6X5kTHkdwC4B         AronChupa   \n",
       "2  spotify:track:0GZoB8h0kqXn7XFm4Sj06k             Lorde   \n",
       "3  spotify:track:35kahykNu00FPysz3C2euR             Lorde   \n",
       "4  spotify:track:3G6hD9B2ZHOsgf4WfNu7X1             Lorde   \n",
       "5  spotify:track:6WQLkih8nE0JdUCEyLaGnQ            Alesso   \n",
       "6  spotify:track:37sINbJZcFdHFAsVNsPq1i        The Script   \n",
       "7  spotify:track:0yhPEz5KxlDwckGJaMlZqM      Fall Out Boy   \n",
       "8  spotify:track:5j9iuo3tMmQIfnEEQOOjxh  American Authors   \n",
       "9  spotify:track:4eLSCSELtKxZwXnFbNLXT5   Imagine Dragons   \n",
       "\n",
       "                                          track_name  \n",
       "0                                       Little Swing  \n",
       "1                                   I'm an Albatraoz  \n",
       "2  Yellow Flicker Beat - From The Hunger Games: M...  \n",
       "3                                  White Teeth Teens  \n",
       "4                                               Team  \n",
       "5                               Heroes (we could be)  \n",
       "6                                        Superheroes  \n",
       "7                                          Centuries  \n",
       "8                                Best Day Of My Life  \n",
       "9                                On Top Of The World  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lyricsgenius import Genius\n",
    "\n",
    "genius = Genius(g6Ycf22ZvPBoLt_IARCcp8_DUVzU0EHrGdgOKV_v9yqFutnG2F3HBoR1UJcoFDal)\n",
    "genius.search_lyrics(df2['artist_name'], df2['track_name'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting File into multiple files of fixed row size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_per_file = 3000  # Number of rows per file\n",
    "\n",
    "# Calculate how many files will be needed\n",
    "num_files = len(df_lyrics) // rows_per_file + (1 if len(df_lyrics) % rows_per_file != 0 else 0)\n",
    "\n",
    "# Split and save the DataFrame into multiple CSV files\n",
    "for i in range(num_files):\n",
    "    start_row = i * rows_per_file\n",
    "    end_row = start_row + rows_per_file\n",
    "    # Create a new CSV file for each chunk\n",
    "    df_lyrics[start_row:end_row].to_csv(f'output_file_{i + 1}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fetching Lyrics from Genius API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import lyricsgenius\n",
    "\n",
    "load_dotenv()\n",
    "token = os.getenv(\"genius_token\")\n",
    "genius = lyricsgenius.Genius(token)\n",
    "genius.remove_section_headers = True # Remove section headers from lyrics when searching\n",
    "genius.timeout = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching lyrics via API\n",
    "for i in range(len(df_lyrics)-66233):\n",
    "    df_lyrics.loc[i, 'lyrics'] = genius.search_song(df_lyrics['track_name'][i], df_lyrics['artist_name'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df_lyrics)-1):\n",
    "    song = genius.search_song(df_lyrics['track_name'][i], df_lyrics['artist_name'][i])\n",
    "    df_lyrics.loc[i, 'lyrics'] = song.lyrics if song else 'Lyrics not found'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lyrics['lyrics'][7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"131 ContributorsTranslationsEspañolFrançaisItalianoPortuguêsTeam Lyrics\\nWait till you're announced\\nWe've not yet lost all our graces\\nThe hounds will stay in chains\\nLook upon Your Greatness and she'll\\nSend the call out, send the call out\\nSend the call out, send the call out\\nSend the call out, send the call out\\nSend the call out, send the call out\\nSend the call out, send the call out\\nSend the call out, send the call out\\nSend the call out, send the call out\\nSend the call out, send the call out\\n\\nCall all the ladies out\\nThey're in their finery\\nA hundred jewels on throats\\nA hundred jewels between teeth\\nNow bring my boys in\\nTheir skin in craters like the moon\\nThe moon we love like a brother\\nWhile he glows through the room\\n\\nDancin' around the lies we tell\\nDancin' around big eyes, as well\\nEven the comatose\\nThey don't dance and tell\\nYou might also like\\nWe live in cities you'll never see on-screen\\nNot very pretty, but we sure know how to run things\\nLivin' in ruins of a palace within my dreams\\nAnd you know, we're on each other's team\\n\\nI'm kind of over gettin' told to throw my hands up in the air\\nSo there\\n\\nSo all the cups got broke\\nShards beneath our feet\\nBut it wasn't my fault\\nAnd everyone's competing\\nFor a love they won't receive\\n'Cause what this palace wants is release\\n\\nWe live in cities you'll never see on-screen\\nNot very pretty, but we sure know how to run things\\nLivin' in ruins of a palace within my dreams\\nAnd you know, we're on each other's team\\n\\nI'm kind of over gettin' told to throw my hands up in the air\\nSo there\\nI'm kind of older than I was when I reveled without a care\\nSo there\\nWe live in cities you'll never see on-screen\\nNot very pretty, but we sure know how to run things\\nLivin' in ruins of a palace within my dreams\\nAnd you know, we're on each other's team\\n\\nWe're on each other's team\\nAnd you know, we're on each other's team\\nWe're on each other's team\\nAnd you know, and you know, and you know330Embed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lyrics['lyrics'].isna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lyricsgenius\n",
    "\n",
    "# Initialize Genius API\n",
    "genius = lyricsgenius.Genius('put_your_token_here')\n",
    "\n",
    "genius.remove_section_headers = True\n",
    "\n",
    "# Spotify Global Top 50 playlist ID\n",
    "playlist_id = '37i9dQZEVXbMDoHDwVN2tF'  # Example ID, update as necessary\n",
    "\n",
    "results = sp.playlist_tracks(playlist_id)\n",
    "tracks_data = []\n",
    "\n",
    "# Fetch track details from Spotify\n",
    "for item in results['items']:\n",
    "    track = item['track']\n",
    "    track_info = {\n",
    "        'Name': track['name'],\n",
    "        'Artist': track['artists'][0]['name'] if track['artists'] else 'Unknown',\n",
    "        'Album': track['album']['name'] if track['album'] else 'Unknown',\n",
    "        'Release Date': track['album']['release_date'] if track['album'] else 'Unknown',\n",
    "        'Popularity': track['popularity']\n",
    "    }\n",
    "    # Fetch lyrics using Genius\n",
    "    song = genius.search_song(track_info['Name'], track_info['Artist'])\n",
    "    track_info['Lyrics'] = song.lyrics if song else 'Lyrics not found'\n",
    "    \n",
    "    tracks_data.append(track_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the lyrics column if it doesn't exist\n",
    "if 'lyrics' not in df_lyrics.columns:\n",
    "    df_lyrics['lyrics'] = None\n",
    "\n",
    "# Defining batch size for progress tracking\n",
    "batch_size = 100\n",
    "num_batches = (len(df_lyrics) + batch_size - 1) // batch_size  # Calculate total number of batches\n",
    "\n",
    "# Processing each song in df_lyrics\n",
    "for i in range(len(df_lyrics)):\n",
    "    if pd.isna(df_lyrics.at[i, 'lyrics']):  # Check if lyrics already fetched to avoid refetching\n",
    "        try:\n",
    "            song = genius.search_song(df_lyrics.at[i, 'track_name'], df_lyrics.at[i, 'artist_name'])\n",
    "            df_lyrics.at[i, 'lyrics'] = song.lyrics if song else 'Lyrics not found'\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching lyrics for row {i}: {e}\")\n",
    "            df_lyrics.at[i, 'lyrics'] = 'Error fetching lyrics'\n",
    "    # Checking print progress\n",
    "    if i % batch_size == 0 or i == len(df_lyrics) - 1:\n",
    "        print(f\"Processed {i+1}/{len(df_lyrics)} songs, Batch {i // batch_size + 1}/{num_batches}\")\n",
    "\n",
    "# Saving complete DataFrame with lyrics to a new file\n",
    "df_lyrics.to_csv('df_final.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save DataFrame to CSV file\n",
    "df_lyrics.to_csv('spotify_lyrics.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lyrics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''import pandas as pd\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "\n",
    "# Initialize spotipy with Spotify API credentials\n",
    "client_id = '5093ad0ad45f435ca7ce43b2afd406b9'  # Replace with your client ID\n",
    "client_secret = 'f151962f414144aa85494be81ccd8e20'  # Replace with your client secret\n",
    "client_credentials_manager = SpotifyClientCredentials(client_id=client_id, client_secret=client_secret)\n",
    "sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)'''\n",
    "\n",
    "# Function to fetch artist name and track name\n",
    "def fetch_tracks_details(track_uris):\n",
    "    try:\n",
    "        tracks_info = sp.tracks(track_uris)\n",
    "        results = []\n",
    "        for track in tracks_info['tracks']:\n",
    "            if track:  # Check if track details are successfully retrieved\n",
    "                artist_name = track['artists'][0]['name'] if track['artists'] else 'Unknown'\n",
    "                track_name = track['name'] if track else 'Unknown'\n",
    "                results.append((artist_name, track_name))\n",
    "            else:\n",
    "                results.append(('Unknown', 'Unknown'))\n",
    "        return results\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing batch: {str(e)}\")\n",
    "        return [('Unknown', 'Unknown')] * len(track_uris)\n",
    "\n",
    "# Apply batch processing\n",
    "batch_size = 50\n",
    "artist_names = []\n",
    "track_names = []\n",
    "\n",
    "for i in range(0, len(df_lyrics['track_uri']), batch_size):\n",
    "    batch_uris = df_lyrics['track_uri'][i:i + batch_size].tolist()\n",
    "    batch_results = fetch_tracks_details(batch_uris)\n",
    "    artist_names.extend([res[0] for res in batch_results])\n",
    "    track_names.extend([res[1] for res in batch_results])\n",
    "\n",
    "df_lyrics['alb_name'] = artist_names\n",
    "df_lyrics['trk_name'] = track_names\n",
    "\n",
    "# Save the updated DataFrame\n",
    "df_lyrics.to_csv('df_lyrics_updated.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
